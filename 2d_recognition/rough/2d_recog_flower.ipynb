{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To increase cell width of ipynb\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudhakaran/Desktop/3d_recognition_thesis/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sudhakaran/Desktop/3d_recognition_thesis/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sudhakaran/Desktop/3d_recognition_thesis/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sudhakaran/Desktop/3d_recognition_thesis/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sudhakaran/Desktop/3d_recognition_thesis/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sudhakaran/Desktop/3d_recognition_thesis/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "import gzip\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DEN():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.last_label_index = 0    # tracks the label index upto which the model has been trained\n",
    "        self.params = dict()\n",
    "        self.k_ex = 5\n",
    "        self.den_layers = 3\n",
    "        self.conv_layers = 2\n",
    "        tf.reset_default_graph()\n",
    "        self.sess = None\n",
    "        self.train = []\n",
    "        self.train_labels = []\n",
    "        self.test = []\n",
    "        self.test_labels = []\n",
    "        self.selected = dict()\n",
    "        self.lr = 1e-3\n",
    "        self.l2_mu = 0.001\n",
    "        self.lamba_regular = 0.5\n",
    "        self.l1_thr = 0.00001\n",
    "        self.loss_thr = 0.01\n",
    "        self.IMG_SIZE = 100\n",
    "        self.IMG_SHAPE = (self.IMG_SIZE, self.IMG_SIZE, 3)\n",
    "\n",
    "    def extract_data(self, filepath):\n",
    "        data = []\n",
    "        data_labels = []\n",
    "        IMG_SIZE = 100\n",
    "        IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "        vgg = tf.keras.applications.VGG16(input_shape=IMG_SHAPE, weights=\"imagenet\", include_top=False)\n",
    "        vgg.trainable = False\n",
    "        for label in os.listdir(filepath):\n",
    "            label_path = os.path.join(filepath, label)\n",
    "            count = 0\n",
    "            list = len(os.listdir(label_path))\n",
    "            for img in os.listdir(label_path):\n",
    "                image_path = os.path.join(label_path, img)\n",
    "                image = cv.imread(image_path)\n",
    "                re_image = cv.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "                # grayImage = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "                # (thresh, BW) = cv.threshold(grayImage, 127, 255, cv.THRESH_BINARY)\n",
    "                data.append(re_image)\n",
    "                data_labels.append(label)\n",
    "\n",
    "        data = np.array(data, dtype=\"float\") / 255.0\n",
    "        features = vgg.predict(data, batch_size=32)\n",
    "        features_flatten = features.reshape((features.shape[0], 3 * 3 * 512))\n",
    "        # data = data.reshape(data.shape[0], 50, 50, 3)\n",
    "        data_labels = np.array(data_labels)\n",
    "        label_names = np.unique(data_labels)\n",
    "        # data_labels = tf.one_hot(indices=data_labels, depth=10)\n",
    "        print(features_flatten.shape)\n",
    "        return features_flatten, data_labels, label_names\n",
    "\n",
    "\n",
    "    def add_task(self, task_id, label_names, initial_output=2):\n",
    "\n",
    "        new_label_indices = []\n",
    "        self.train = []\n",
    "        self.train_labels = []\n",
    "        self.train_ex_labels = []      \n",
    " \n",
    "        if task_id == 1:\n",
    "            self.new_train = []\n",
    "            self.new_train_labels = []\n",
    "            self.new_train_ex_labels = []\n",
    "            self.total = []\n",
    "            self.total_ex_labels = []\n",
    "            self.test = []\n",
    "            self.test_labels = []\n",
    "            for i in range(initial_output):   # By default, first task is a binary classification\n",
    "                new_label_indices.append(i)\n",
    "            self.last_label_index = i\n",
    "\n",
    "        else:\n",
    "            new_label_indices.append(self.last_label_index+1)\n",
    "            self.last_label_index = self.last_label_index + 1\n",
    "            \n",
    "            #saving the old training data\n",
    "            self.total = self.total + self.new_train\n",
    "            self.total_ex_labels = self.total_ex_labels + self.new_train_ex_labels\n",
    "            self.new_train = []\n",
    "            self.new_train_labels = []\n",
    "            self.new_train_ex_labels = []\n",
    "\n",
    "        for index in new_label_indices:\n",
    "            print(\" \\n Added new category: \"+str(label_names[index]))\n",
    "            l = 1 if task_id != 1 else index\n",
    "            for data, label in zip(train_data, train_labels):\n",
    "                if label_names[index] == label:\n",
    "                    self.new_train.append(data)\n",
    "                    self.new_train_labels.append(l)\n",
    "                    self.new_train_ex_labels.append(index)\n",
    "\n",
    "            for data, label in zip(test_data, test_labels):\n",
    "                if label_names[index] == label:\n",
    "                    self.test.append(data)\n",
    "                    self.test_labels.append(index)\n",
    "                    \n",
    "        # ------------------ Random sampling old training data ------------------\n",
    "        if task_id != 1:\n",
    "            sampled_indices = random.sample(range(len(self.total)), len(self.new_train))\n",
    "            for k in sampled_indices:\n",
    "                self.train.append(self.total[k])\n",
    "                self.train_labels.append(0)\n",
    "                self.train_ex_labels.append(self.total_ex_labels[k])\n",
    "                \n",
    "            self.train = self.train + self.new_train\n",
    "            self.train_labels = self.train_labels + self.new_train_labels\n",
    "            self.train_ex_labels = self.train_ex_labels + self.new_train_ex_labels\n",
    "        else:\n",
    "            self.train = self.new_train\n",
    "            self.train_labels = self.new_train_labels\n",
    "            self.train_ex_labels = self.new_train_ex_labels\n",
    "                \n",
    "\n",
    "    def destroy_graph(self):\n",
    "        tf.reset_default_graph()\n",
    "        self.params = dict()\n",
    "\n",
    "    def initialize_parameters(self, output_len=2):\n",
    "        self.sess = tf.Session()\n",
    "        self.x = tf.placeholder(tf.float32, [None, 3 * 3 * 512])\n",
    "        self.y_ = tf.placeholder(tf.float32, [None, output_len])\n",
    "        # self.keep_prob = tf.placeholder(tf.float32)          # dropout probability\n",
    "\n",
    "    def create_variable(self, name=None, shape=None, scope=None, trainable=True):\n",
    "        with tf.variable_scope(scope, reuse=False):\n",
    "            w = tf.get_variable(name, shape=shape, \n",
    "#                                 initializer=tf.random_normal_initializer(mean=0, stddev=1, seed=3),\n",
    "                                trainable=trainable)\n",
    "            if \"ex\" not in name:\n",
    "                self.params[w.name] = w\n",
    "        return w\n",
    "\n",
    "    def get_variable(self, name=None, scope=None):\n",
    "        with tf.variable_scope(scope, reuse=True):\n",
    "            w = tf.get_variable(name)\n",
    "            if \"ex\" not in name:\n",
    "                self.params[w.name] = w\n",
    "        return w\n",
    "\n",
    "    def restore_params(self, task_id=None, trainable=True, param_values=dict()):\n",
    "        self.params = dict()\n",
    "        self.prev_W = dict()\n",
    "        for scope_name, value in param_values.items():\n",
    "            self.prev_W[scope_name] = value\n",
    "            scope_name = scope_name.split(':')[0]\n",
    "            [scope, name] = scope_name.split('/')\n",
    "\n",
    "            if task_id != None:\n",
    "                if ('l%d/w_%d' % (self.den_layers,task_id) in scope_name) or ('l%d/b_%d' % (self.den_layers,task_id) in scope_name):\n",
    "                    trainable = True\n",
    "                else:\n",
    "                    trainable = False\n",
    "\n",
    "            with tf.variable_scope(scope, reuse=False):\n",
    "                w = tf.get_variable(name, initializer=value, trainable=trainable)\n",
    "            self.params[w.name] = w\n",
    "\n",
    "    def get_params(self):\n",
    "        vdict = dict()\n",
    "        for scope_name, ref_w in self.params.items():\n",
    "            vdict[scope_name] = self.sess.run(ref_w)\n",
    "        return vdict\n",
    "\n",
    "    def conv2d(self, x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    def max_pool_2x2(self, x):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "    def build_model(self, task_id, expansion=False, output_len=2):\n",
    "\n",
    "        # Note: scope and name values are only given to DEN layers, not for fixed sized layers.\n",
    "\n",
    "        self.initialize_parameters(output_len)\n",
    "\n",
    "        if task_id == 1:\n",
    "\n",
    "            #flattened first fc layer\n",
    "            W_fc1 = self.create_variable(name=\"w\", shape=[3 * 3 * 512, 1024], scope=\"l1\")   # layer-1 outgoing weight matrix\n",
    "            b_fc1 = self.create_variable(name=\"b\", shape=[1024], scope=\"l1\")\n",
    "\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(self.x, W_fc1) + b_fc1)\n",
    "\n",
    "            #second fc layer\n",
    "            W_fc2 = self.create_variable(name=\"w\", shape=[1024, 128], scope=\"l2\")   # layer-2 outgoing weight matrix\n",
    "            b_fc2 = self.create_variable(name=\"b\", shape=[128], scope=\"l2\")\n",
    "\n",
    "            self.h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "            # readout fc layer\n",
    "            self.w_fc = self.create_variable(name=\"w\", shape=[128, output_len], scope=\"l3\")     # layer-3 outgoing weight matrix \n",
    "            self.b_fc = self.create_variable(name=\"b\", shape=[output_len], scope=\"l3\")\n",
    "            y_conv = tf.matmul(self.h_fc2, self.w_fc) + self.b_fc\n",
    "            \n",
    "        elif expansion:\n",
    "            \n",
    "            # fc layer expansion\n",
    "            for layer in range(1, self.den_layers+1):\n",
    "\n",
    "                if layer == 1:\n",
    "                    w_fc1 = self.get_variable(name=\"w\", scope=\"l%d\"%layer)\n",
    "                    b_fc1 = self.get_variable(name=\"b\", scope=\"l%d\"%layer)\n",
    "\n",
    "\n",
    "                    w_expand = self.create_variable(name=\"w_ex_\"+str(task_id),shape=[w_fc1.get_shape().as_list()[0], self.k_ex], scope=\"l\"+str(layer))\n",
    "                    b_expand = self.create_variable(name=\"b_ex_\"+str(task_id),shape=[self.k_ex], scope=\"l%d\"%layer)\n",
    "                    w_expanded = tf.concat([w_fc1,w_expand],1)\n",
    "                    b_expanded = tf.concat([b_fc1,b_expand],0)\n",
    "                    self.params[w_fc1.name] = w_expanded\n",
    "                    self.params[b_fc1.name] = b_expanded\n",
    "                    h_fc1 = tf.nn.relu(tf.matmul(self.x, w_expanded) + b_expanded)\n",
    "\n",
    "                elif layer == self.den_layers:\n",
    "                    #weight matrix of current task output\n",
    "                    w_fc3 = self.get_variable(name=\"w_%d\"%task_id,scope=\"l%d\"%layer)\n",
    "                    b_fc3 = self.get_variable(name=\"b_%d\"%task_id,scope=\"l%d\"%layer)\n",
    "                    prev_dim = w_fc3.get_shape().as_list()[0]\n",
    "                    next_dim = w_fc3.get_shape().as_list()[1]\n",
    "                    \n",
    "                    #weight matrix of old tasks output\n",
    "                    w_fc3_old = self.get_variable(name=\"w\",scope=\"l%d\"%layer)\n",
    "                    b_fc3_old = self.get_variable(name=\"b\",scope=\"l%d\"%layer)\n",
    "                    prev_old = w_fc3_old.get_shape().as_list()[0]\n",
    "                    next_old = w_fc3_old.get_shape().as_list()[1]\n",
    "                    \n",
    "                    w_merge = tf.concat([w_fc3_old, w_fc3], 1)\n",
    "                    b_merge = tf.concat([b_fc3_old, b_fc3], 0)\n",
    "                    \n",
    "                    w_expand = self.create_variable(name=\"w_ex_\"+str(task_id), shape=[self.k_ex, next_old+next_dim], scope=\"l%d\"%layer)\n",
    "                    w_expanded = tf.concat([w_merge, w_expand], 0)\n",
    "                    \n",
    "                    self.params[w_fc3_old.name] = w_expanded\n",
    "                    self.params[b_fc3_old.name] = b_merge\n",
    "                    \n",
    "                    y_conv = tf.matmul(self.h_fc2, w_expanded) + b_merge\n",
    "\n",
    "                else:\n",
    "                    w_fc2 = self.get_variable(name=\"w\",scope=\"l%d\"%layer)\n",
    "                    b_fc2 = self.get_variable(name=\"b\",scope=\"l%d\"%layer)\n",
    "\n",
    "                    prev_dim = w_fc2.get_shape().as_list()[0]\n",
    "                    next_dim = w_fc2.get_shape().as_list()[1]\n",
    "                    \n",
    "                    # Dummy nodes for prev hidden nodes\n",
    "                    dummy_w = tf.get_variable(name=\"dummy_t%d_l%d\" %(task_id,layer), shape=[self.k_ex, next_dim], \n",
    "                                initializer=tf.constant_initializer(0.0), trainable=False)\n",
    "\n",
    "                    w_expand = self.create_variable(name=\"w_ex_\"+str(task_id), shape=[prev_dim + self.k_ex, self.k_ex], scope=\"l%d\"%layer)\n",
    "                    b_expand = self.create_variable(name=\"b_ex_\"+str(task_id), shape=[self.k_ex], scope=\"l%d\"%layer)\n",
    "                    \n",
    "                    w_fc2_dummy = tf.concat([w_fc2, dummy_w],0)\n",
    "                    \n",
    "                    w_expanded = tf.concat([w_fc2_dummy, w_expand], 1)\n",
    "                    b_expanded = tf.concat([b_fc2, b_expand], 0)\n",
    "                    \n",
    "                    self.params[w_fc2.name] = w_expanded\n",
    "                    self.params[b_fc2.name] = b_expanded\n",
    "                    self.h_fc2 = tf.nn.relu(tf.matmul(h_fc1, w_expanded) + b_expanded)\n",
    "                    \n",
    "        else:\n",
    "\n",
    "            #flattened first fc layer\n",
    "            W_fc1 = self.get_variable(name=\"w\", scope=\"l1\")   # layer-1 outgoing weight matrix\n",
    "            b_fc1 = self.get_variable(name=\"b\", scope=\"l1\")\n",
    "\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(self.x, W_fc1) + b_fc1)\n",
    "\n",
    "            #second fc layer\n",
    "            W_fc2 = self.get_variable(name=\"w\", scope=\"l2\")   # layer-2 outgoing weight matrix\n",
    "            b_fc2 = self.get_variable(name=\"b\", scope=\"l2\")\n",
    "\n",
    "            self.h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "            self.w_fc = self.create_variable(name=\"w_\"+str(task_id), shape=[self.h_fc2.shape[1], output_len], scope=\"l3\", trainable=True)     # layer-3 outgoing weight matrix \n",
    "            self.b_fc = self.create_variable(name=\"b_\"+str(task_id), shape=[output_len], scope=\"l3\", trainable=True)\n",
    "            y_conv = tf.matmul(self.h_fc2, self.w_fc) + self.b_fc\n",
    "\n",
    "#         y_conv = tf.nn.sigmoid(y_conv)\n",
    "        return y_conv\n",
    "    \n",
    "    def perform_selection(self, task_id, values_dict):      # Breadth first search for selecting non-zero units\n",
    "        \n",
    "        all_indices = defaultdict(list)     # to store indices of nonzero units\n",
    "        selected_params = dict()            # to store values of nonzero units\n",
    "        selected_prev_params = dict()\n",
    "        \n",
    "#         for scope, value in values_dict.items():    # Storing conv layers in selected parameters \n",
    "#             if \"conv\" in scope:\n",
    "#                 selected_params[scope] = value\n",
    "            \n",
    "        for i in reversed(range(1,self.den_layers+1)):\n",
    "            if i == self.den_layers:\n",
    "                w = values_dict['l%d/w_%d:0' %(i,task_id)]\n",
    "                b = values_dict['l%d/b_%d:0' %(i,task_id)]\n",
    "                for j in range(w.shape[0]):\n",
    "                    if w[j,0] != 0:\n",
    "                        all_indices['l%d' % i].append(j)\n",
    "                # np.ix_(): fancy indexing, index with arrays of integers\n",
    "                # Select non-zero weights between the last hidden layer and the output layer\n",
    "                selected_params['l%d/w_%d:0' % (i, task_id)] = \\\n",
    "                    w[np.ix_(all_indices['l%d' % i], [0])]\n",
    "                selected_params['l%d/b_%d:0' % (i, task_id)] = b\n",
    "            else:\n",
    "                w = values_dict['l%d/w:0' % i]\n",
    "                b = values_dict['l%d/b:0' % i]\n",
    "                top_indices = all_indices['l%d' % (i + 1)]\n",
    "                print(len(top_indices))\n",
    "                for j in range(w.shape[0]):\n",
    "                    if np.count_nonzero(w[j, top_indices]) != 0 or i == 1:\n",
    "                        all_indices['l%d' % i].append(j)\n",
    "                \n",
    "                # non-zero weights between the layer i and the layer i+1\n",
    "                sub_weight = w[np.ix_(all_indices['l%d' % i], top_indices)]\n",
    "                sub_biases = b[all_indices['l%d' % (i + 1)]]\n",
    "                selected_params['l%d/w:0' % i] = sub_weight\n",
    "                selected_params['l%d/b:0' % i] = sub_biases\n",
    "                \n",
    "                # prev_W : to avoid drastic change in value of weights (Regularization)\n",
    "                selected_prev_params['l%d/w:0' % i] = \\\n",
    "                    self.prev_W['l%d/w:0' % i][np.ix_(all_indices['l%d' % i], top_indices)]\n",
    "                selected_prev_params['l%d/b:0' % i] = \\\n",
    "                    self.prev_W['l%d/b:0' % i][all_indices['l%d' % (i + 1)]]\n",
    "\n",
    "#         for keys, value in selected_params.items():\n",
    "#             print(keys)\n",
    "#             print(value)\n",
    "                \n",
    "        return [selected_params, selected_prev_params, all_indices]\n",
    "        \n",
    "    def build_SR(self, task_id, selected, output_len):    # creating selective retraining model\n",
    "        \n",
    "        self.initialize_parameters(output_len)\n",
    "        h = self.x\n",
    "        \n",
    "        for i in range(1, self.den_layers):\n",
    "            with tf.variable_scope('l%d' % i):\n",
    "                w = tf.get_variable('w', initializer=selected['l%d/w:0' % i], trainable=True)\n",
    "                b = tf.get_variable('b', initializer=selected['l%d/b:0' % i], trainable=True)\n",
    "            h = tf.nn.relu(tf.matmul(h, w) + b)\n",
    "            \n",
    "        # last layer\n",
    "        with tf.variable_scope('l%d' % self.den_layers):\n",
    "            w = tf.get_variable('w_%d' % task_id,\n",
    "                                initializer=selected['l%d/w_%d:0' % (self.den_layers, task_id)], trainable=True)\n",
    "            b = tf.get_variable('b_%d' % task_id,\n",
    "                                initializer=selected['l%d/b_%d:0' % (self.den_layers, task_id)], trainable=True)\n",
    "\n",
    "        y_conv = tf.matmul(h, w) + b\n",
    "#         y_conv = tf.nn.sigmoid(y_conv)\n",
    "        return y_conv\n",
    "\n",
    "    def optimization(self, prev_W=None):\n",
    "\n",
    "        l2_regular = 0\n",
    "        train_var = []\n",
    "        regular_terms = []\n",
    "        \n",
    "        self.loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(labels=self.y_, logits=y_conv))\n",
    "\n",
    "#         for var in tf.trainable_variables():\n",
    "#             l2_regular = l2_regular + tf.nn.l1_loss(var)\n",
    "#             train_var.append(var)\n",
    "#         print(len(train_var))\n",
    "\n",
    "        l1_var = [var for var in tf.trainable_variables()]\n",
    "        regularizer = tf.contrib.layers.l1_regularizer(self.l2_mu)\n",
    "        reg_term = tf.contrib.layers.apply_regularization(regularizer, l1_var)\n",
    "        self.loss = self.loss + reg_term\n",
    "#         self.loss = self.loss + tf.reduce_mean(self.l2_mu * l2_regular)\n",
    "\n",
    "        if prev_W != None:\n",
    "            for var in l1_var:\n",
    "                if var.name in prev_W.keys():\n",
    "                    prev_w = prev_W[var.name]\n",
    "                    regular_terms.append(tf.nn.l2_loss(var - prev_w))\n",
    "            self.loss = self.loss + self.lamba_regular * tf.reduce_mean(regular_terms)\n",
    "        \n",
    "        opt = tf.train.AdamOptimizer(self.lr)\n",
    "        grads = opt.compute_gradients(self.loss, l1_var)\n",
    "        apply_grads = opt.apply_gradients(grads)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(self.y_,1))\n",
    "        self.acc_train = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "#         l1_var = [var for var in tf.trainable_variables()]\n",
    "        l1_op_list = []\n",
    "        with tf.control_dependencies([apply_grads]):  # exec apply_grads first\n",
    "            for var in tf.trainable_variables():\n",
    "                th_t = tf.fill(tf.shape(var), tf.convert_to_tensor(self.l1_thr))\n",
    "                zero_t = tf.zeros(tf.shape(var))\n",
    "#                 var_temp = var - (th_t * tf.sign(var))\n",
    "                # [pseudo]:  if |var| < th_t: var = [0];  else: var = var_temp\n",
    "                l1_op = var.assign(tf.where(tf.less(tf.abs(var), th_t), zero_t, var))\n",
    "                l1_op_list.append(l1_op)\n",
    "        \n",
    "        with tf.control_dependencies(l1_op_list):\n",
    "            self.train_model = tf.no_op()\n",
    "\n",
    "    def train_task(self, task_id, batch_size, epochs, expansion=False):\n",
    "\n",
    "        if task_id == 1:\n",
    "            task_train_labels = tf.one_hot(indices=np.array(self.train_labels), depth=self.last_label_index+1)\n",
    "        elif expansion:\n",
    "            task_train_labels = tf.one_hot(indices=np.array(self.train_ex_labels), depth=self.last_label_index+1)\n",
    "        else:\n",
    "            task_train_labels = np.array(self.train_labels)\n",
    "            task_train_labels = task_train_labels.reshape((task_train_labels.shape[0],1))\n",
    "            task_train_labels = tf.convert_to_tensor(task_train_labels)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((np.array(self.train), task_train_labels))\n",
    "        dataset = dataset.shuffle(len(self.train_labels)).repeat().batch(batch_size)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        (x_data , y_data) = iterator.get_next()\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        task_train_labels = self.sess.run(task_train_labels)\n",
    "        count = 0\n",
    "\n",
    "#         for scope, ref in self.params.items():\n",
    "#             if \"l2\" in scope:\n",
    "#                 print(self.sess.run(ref))\n",
    "\n",
    "        for i in range(epochs):\n",
    "\n",
    "            for j in range(int(len(self.train)/batch_size)):\n",
    "                x_batch , y_batch = self.sess.run([x_data,y_data])\n",
    "                _, loss = self.sess.run([self.train_model, self.loss], feed_dict={self.x: x_batch, self.y_: y_batch})\n",
    "\n",
    "            train_accuracy = self.acc_train.eval(session=self.sess, feed_dict={self.x: self.train, self.y_: task_train_labels})\n",
    "            print(\"Epoch %d, training accuracy %g\"%(i+1, train_accuracy))\n",
    "\n",
    "            if train_accuracy == 1:\n",
    "                count += 1\n",
    "\n",
    "                if count > 4:\n",
    "                    print(\"Best accuracy achieved! \\n\")\n",
    "                    break\n",
    "        \n",
    "#         for scope, ref in self.params.items():\n",
    "#             if \"l2\" in scope:\n",
    "#                 print(self.sess.run(ref))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def predict(self, task_id, output_len=2):\n",
    "\n",
    "        self.initialize_parameters(output_len)\n",
    "\n",
    "        task_test_labels = tf.one_hot(indices=self.test_labels, depth=self.last_label_index+1)\n",
    "        task_test_labels = self.sess.run(task_test_labels)\n",
    "        \n",
    "        #flattened first fc layer\n",
    "        W_fc1 = self.get_variable(name=\"w\", scope=\"l1\")   # layer-1 outgoing weight matrix\n",
    "        b_fc1 = self.get_variable(name=\"b\", scope=\"l1\")\n",
    "\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(self.x, W_fc1) + b_fc1)\n",
    "\n",
    "        #second fc layer\n",
    "        W_fc2 = self.get_variable(name=\"w\", scope=\"l2\")   # layer-2 outgoing weight matrix\n",
    "        b_fc2 = self.get_variable(name=\"b\", scope=\"l2\")\n",
    "\n",
    "        self.h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "        self.w_fc = self.get_variable(name=\"w\", scope=\"l3\")\n",
    "        self.b_fc = self.get_variable(name=\"b\", scope=\"l3\")\n",
    "\n",
    "        y_final = tf.matmul(self.h_fc2, self.w_fc) + self.b_fc\n",
    "        y_final = tf.nn.sigmoid(y_final)\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(y_final,1), tf.argmax(self.y_,1))\n",
    "        self.acc_test = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        test_accuracy = self.acc_test.eval(session=self.sess, feed_dict={self.x: self.test, self.y_: task_test_labels})\n",
    "        print(\"Overall accuracy: %g \\n\"%test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..........loading dataset from numpy files..........\n",
      "\n",
      " \n",
      " Added new category: alpine sea holly\n",
      " \n",
      " Added new category: anthurium\n",
      "-------------Training new task: 1--------------\n",
      "WARNING:tensorflow:From /home/sudhakaran/Desktop/3d_recognition_thesis/2d_recognition/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Epoch 1, training accuracy 0.982609\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Epoch 6, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "Overall accuracy: 1 \n",
      "\n",
      " \n",
      " Added new category: artichoke\n",
      "-------------Training new task: 2--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.653226\n",
      "Epoch 2, training accuracy 0.66129\n",
      "Epoch 3, training accuracy 0.677419\n",
      "Epoch 4, training accuracy 0.637097\n",
      "Epoch 5, training accuracy 0.58871\n",
      "Epoch 6, training accuracy 0.66129\n",
      "Epoch 7, training accuracy 0.596774\n",
      "Epoch 8, training accuracy 0.596774\n",
      "Epoch 9, training accuracy 0.604839\n",
      "Epoch 10, training accuracy 0.596774\n",
      "Epoch 11, training accuracy 0.596774\n",
      "Epoch 12, training accuracy 0.596774\n",
      "Epoch 13, training accuracy 0.596774\n",
      "Epoch 14, training accuracy 0.596774\n",
      "Epoch 15, training accuracy 0.612903\n",
      "Epoch 16, training accuracy 0.596774\n",
      "Epoch 17, training accuracy 0.604839\n",
      "Epoch 18, training accuracy 0.612903\n",
      "Epoch 19, training accuracy 0.637097\n",
      "Epoch 20, training accuracy 0.66129\n",
      "Epoch 21, training accuracy 0.66129\n",
      "Epoch 22, training accuracy 0.66129\n",
      "Epoch 23, training accuracy 0.66129\n",
      "Epoch 24, training accuracy 0.66129\n",
      "Epoch 25, training accuracy 0.677419\n",
      "Epoch 26, training accuracy 0.685484\n",
      "Epoch 27, training accuracy 0.717742\n",
      "Epoch 28, training accuracy 0.717742\n",
      "Epoch 29, training accuracy 0.725806\n",
      "Epoch 30, training accuracy 0.758065\n",
      "Epoch 31, training accuracy 0.766129\n",
      "Epoch 32, training accuracy 0.766129\n",
      "Epoch 33, training accuracy 0.782258\n",
      "Epoch 34, training accuracy 0.806452\n",
      "Epoch 35, training accuracy 0.806452\n",
      "Epoch 36, training accuracy 0.806452\n",
      "Epoch 37, training accuracy 0.822581\n",
      "Epoch 38, training accuracy 0.822581\n",
      "Epoch 39, training accuracy 0.822581\n",
      "Epoch 40, training accuracy 0.822581\n",
      "Epoch 41, training accuracy 0.822581\n",
      "Epoch 42, training accuracy 0.830645\n",
      "Epoch 43, training accuracy 0.830645\n",
      "Epoch 44, training accuracy 0.830645\n",
      "Epoch 45, training accuracy 0.846774\n",
      "Epoch 46, training accuracy 0.830645\n",
      "Epoch 47, training accuracy 0.830645\n",
      "Epoch 48, training accuracy 0.822581\n",
      "Epoch 49, training accuracy 0.822581\n",
      "Epoch 50, training accuracy 0.83871\n",
      "Overall accuracy: 0.769231 \n",
      "\n",
      " \n",
      " Added new category: azalea\n",
      "-------------Training new task: 3--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.714286\n",
      "Epoch 2, training accuracy 0.714286\n",
      "Epoch 3, training accuracy 0.714286\n",
      "Epoch 4, training accuracy 0.720779\n",
      "Epoch 5, training accuracy 0.818182\n",
      "Epoch 6, training accuracy 0.824675\n",
      "Epoch 7, training accuracy 0.824675\n",
      "Epoch 8, training accuracy 0.87013\n",
      "Epoch 9, training accuracy 0.844156\n",
      "Epoch 10, training accuracy 0.909091\n",
      "Epoch 11, training accuracy 0.915584\n",
      "Epoch 12, training accuracy 0.915584\n",
      "Epoch 13, training accuracy 0.928571\n",
      "Epoch 14, training accuracy 0.928571\n",
      "Epoch 15, training accuracy 0.954545\n",
      "Epoch 16, training accuracy 0.941558\n",
      "Epoch 17, training accuracy 0.948052\n",
      "Epoch 18, training accuracy 0.928571\n",
      "Epoch 19, training accuracy 0.948052\n",
      "Epoch 20, training accuracy 0.954545\n",
      "Epoch 21, training accuracy 0.948052\n",
      "Epoch 22, training accuracy 0.948052\n",
      "Epoch 23, training accuracy 0.948052\n",
      "Epoch 24, training accuracy 0.967532\n",
      "Epoch 25, training accuracy 0.967532\n",
      "Epoch 26, training accuracy 0.967532\n",
      "Epoch 27, training accuracy 0.967532\n",
      "Epoch 28, training accuracy 0.967532\n",
      "Epoch 29, training accuracy 0.967532\n",
      "Epoch 30, training accuracy 0.961039\n",
      "Epoch 31, training accuracy 0.967532\n",
      "Epoch 32, training accuracy 0.967532\n",
      "Epoch 33, training accuracy 0.967532\n",
      "Epoch 34, training accuracy 0.967532\n",
      "Epoch 35, training accuracy 0.967532\n",
      "Epoch 36, training accuracy 0.967532\n",
      "Epoch 37, training accuracy 0.967532\n",
      "Epoch 38, training accuracy 0.974026\n",
      "Epoch 39, training accuracy 0.967532\n",
      "Epoch 40, training accuracy 0.967532\n",
      "Epoch 41, training accuracy 0.967532\n",
      "Epoch 42, training accuracy 0.967532\n",
      "Epoch 43, training accuracy 0.974026\n",
      "Epoch 44, training accuracy 0.974026\n",
      "Epoch 45, training accuracy 0.967532\n",
      "Epoch 46, training accuracy 0.974026\n",
      "Epoch 47, training accuracy 0.974026\n",
      "Epoch 48, training accuracy 0.974026\n",
      "Epoch 49, training accuracy 0.974026\n",
      "Epoch 50, training accuracy 0.974026\n",
      "Overall accuracy: 0.864865 \n",
      "\n",
      " \n",
      " Added new category: ball moss\n",
      "-------------Training new task: 4--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.764706\n",
      "Epoch 2, training accuracy 0.808824\n",
      "Epoch 3, training accuracy 0.779412\n",
      "Epoch 4, training accuracy 0.779412\n",
      "Epoch 5, training accuracy 0.779412\n",
      "Epoch 6, training accuracy 0.808824\n",
      "Epoch 7, training accuracy 0.838235\n",
      "Epoch 8, training accuracy 0.764706\n",
      "Epoch 9, training accuracy 0.764706\n",
      "Epoch 10, training accuracy 0.794118\n",
      "Epoch 11, training accuracy 0.823529\n",
      "Epoch 12, training accuracy 0.823529\n",
      "Epoch 13, training accuracy 0.75\n",
      "Epoch 14, training accuracy 0.779412\n",
      "Epoch 15, training accuracy 0.808824\n",
      "Epoch 16, training accuracy 0.808824\n",
      "Epoch 17, training accuracy 0.808824\n",
      "Epoch 18, training accuracy 0.808824\n",
      "Epoch 19, training accuracy 0.75\n",
      "Epoch 20, training accuracy 0.823529\n",
      "Epoch 21, training accuracy 0.823529\n",
      "Epoch 22, training accuracy 0.838235\n",
      "Epoch 23, training accuracy 0.823529\n",
      "Epoch 24, training accuracy 0.823529\n",
      "Epoch 25, training accuracy 0.838235\n",
      "Epoch 26, training accuracy 0.867647\n",
      "Epoch 27, training accuracy 0.852941\n",
      "Epoch 28, training accuracy 0.852941\n",
      "Epoch 29, training accuracy 0.838235\n",
      "Epoch 30, training accuracy 0.867647\n",
      "Epoch 31, training accuracy 0.897059\n",
      "Epoch 32, training accuracy 0.852941\n",
      "Epoch 33, training accuracy 0.867647\n",
      "Epoch 34, training accuracy 0.882353\n",
      "Epoch 35, training accuracy 0.911765\n",
      "Epoch 36, training accuracy 0.897059\n",
      "Epoch 37, training accuracy 0.911765\n",
      "Epoch 38, training accuracy 0.955882\n",
      "Epoch 39, training accuracy 0.955882\n",
      "Epoch 40, training accuracy 0.882353\n",
      "Epoch 41, training accuracy 0.955882\n",
      "Epoch 42, training accuracy 0.955882\n",
      "Epoch 43, training accuracy 0.941176\n",
      "Epoch 44, training accuracy 0.970588\n",
      "Epoch 45, training accuracy 0.970588\n",
      "Epoch 46, training accuracy 0.970588\n",
      "Epoch 47, training accuracy 0.970588\n",
      "Epoch 48, training accuracy 0.970588\n",
      "Epoch 49, training accuracy 0.970588\n",
      "Epoch 50, training accuracy 0.970588\n",
      "Overall accuracy: 0.837209 \n",
      "\n",
      " \n",
      " Added new category: balloon flower\n",
      "-------------Training new task: 5--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.671053\n",
      "Epoch 2, training accuracy 0.763158\n",
      "Epoch 3, training accuracy 0.789474\n",
      "Epoch 4, training accuracy 0.763158\n",
      "Epoch 5, training accuracy 0.776316\n",
      "Epoch 6, training accuracy 0.763158\n",
      "Epoch 7, training accuracy 0.763158\n",
      "Epoch 8, training accuracy 0.763158\n",
      "Epoch 9, training accuracy 0.763158\n",
      "Epoch 10, training accuracy 0.763158\n",
      "Epoch 11, training accuracy 0.776316\n",
      "Epoch 12, training accuracy 0.789474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, training accuracy 0.802632\n",
      "Epoch 14, training accuracy 0.789474\n",
      "Epoch 15, training accuracy 0.802632\n",
      "Epoch 16, training accuracy 0.802632\n",
      "Epoch 17, training accuracy 0.802632\n",
      "Epoch 18, training accuracy 0.815789\n",
      "Epoch 19, training accuracy 0.789474\n",
      "Epoch 20, training accuracy 0.789474\n",
      "Epoch 21, training accuracy 0.815789\n",
      "Epoch 22, training accuracy 0.802632\n",
      "Epoch 23, training accuracy 0.789474\n",
      "Epoch 24, training accuracy 0.789474\n",
      "Epoch 25, training accuracy 0.789474\n",
      "Epoch 26, training accuracy 0.789474\n",
      "Epoch 27, training accuracy 0.802632\n",
      "Epoch 28, training accuracy 0.802632\n",
      "Epoch 29, training accuracy 0.789474\n",
      "Epoch 30, training accuracy 0.789474\n",
      "Epoch 31, training accuracy 0.815789\n",
      "Epoch 32, training accuracy 0.815789\n",
      "Epoch 33, training accuracy 0.776316\n",
      "Epoch 34, training accuracy 0.802632\n",
      "Epoch 35, training accuracy 0.815789\n",
      "Epoch 36, training accuracy 0.802632\n",
      "Epoch 37, training accuracy 0.802632\n",
      "Epoch 38, training accuracy 0.776316\n",
      "Epoch 39, training accuracy 0.815789\n",
      "Epoch 40, training accuracy 0.802632\n",
      "Epoch 41, training accuracy 0.815789\n",
      "Epoch 42, training accuracy 0.763158\n",
      "Epoch 43, training accuracy 0.763158\n",
      "Epoch 44, training accuracy 0.828947\n",
      "Epoch 45, training accuracy 0.815789\n",
      "Epoch 46, training accuracy 0.763158\n",
      "Epoch 47, training accuracy 0.776316\n",
      "Epoch 48, training accuracy 0.828947\n",
      "Epoch 49, training accuracy 0.802632\n",
      "Epoch 50, training accuracy 0.802632\n",
      "Overall accuracy: 0.66 \n",
      "\n",
      " \n",
      " Added new category: barbeton daisy\n",
      "-------------Training new task: 6--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.824742\n",
      "Epoch 2, training accuracy 0.85567\n",
      "Epoch 3, training accuracy 0.814433\n",
      "Epoch 4, training accuracy 0.871134\n",
      "Epoch 5, training accuracy 0.876289\n",
      "Epoch 6, training accuracy 0.881443\n",
      "Epoch 7, training accuracy 0.871134\n",
      "Epoch 8, training accuracy 0.886598\n",
      "Epoch 9, training accuracy 0.881443\n",
      "Epoch 10, training accuracy 0.907216\n",
      "Epoch 11, training accuracy 0.902062\n",
      "Epoch 12, training accuracy 0.912371\n",
      "Epoch 13, training accuracy 0.886598\n",
      "Epoch 14, training accuracy 0.860825\n",
      "Epoch 15, training accuracy 0.92268\n",
      "Epoch 16, training accuracy 0.92268\n",
      "Epoch 17, training accuracy 0.917526\n",
      "Epoch 18, training accuracy 0.907216\n",
      "Epoch 19, training accuracy 0.927835\n",
      "Epoch 20, training accuracy 0.927835\n",
      "Epoch 21, training accuracy 0.927835\n",
      "Epoch 22, training accuracy 0.917526\n",
      "Epoch 23, training accuracy 0.92268\n",
      "Epoch 24, training accuracy 0.943299\n",
      "Epoch 25, training accuracy 0.92268\n",
      "Epoch 26, training accuracy 0.927835\n",
      "Epoch 27, training accuracy 0.927835\n",
      "Epoch 28, training accuracy 0.917526\n",
      "Epoch 29, training accuracy 0.917526\n",
      "Epoch 30, training accuracy 0.92268\n",
      "Epoch 31, training accuracy 0.93299\n",
      "Epoch 32, training accuracy 0.938144\n",
      "Epoch 33, training accuracy 0.93299\n",
      "Epoch 34, training accuracy 0.93299\n",
      "Epoch 35, training accuracy 0.92268\n",
      "Epoch 36, training accuracy 0.948454\n",
      "Epoch 37, training accuracy 0.927835\n",
      "Epoch 38, training accuracy 0.943299\n",
      "Epoch 39, training accuracy 0.943299\n",
      "Epoch 40, training accuracy 0.938144\n",
      "Epoch 41, training accuracy 0.948454\n",
      "Epoch 42, training accuracy 0.917526\n",
      "Epoch 43, training accuracy 0.943299\n",
      "Epoch 44, training accuracy 0.938144\n",
      "Epoch 45, training accuracy 0.938144\n",
      "Epoch 46, training accuracy 0.938144\n",
      "Epoch 47, training accuracy 0.943299\n",
      "Epoch 48, training accuracy 0.938144\n",
      "Epoch 49, training accuracy 0.927835\n",
      "Epoch 50, training accuracy 0.943299\n",
      "Overall accuracy: 0.875 \n",
      "\n",
      " \n",
      " Added new category: bearded iris\n",
      "-------------Training new task: 7--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.755814\n",
      "Epoch 2, training accuracy 0.732558\n",
      "Epoch 3, training accuracy 0.755814\n",
      "Epoch 4, training accuracy 0.744186\n",
      "Epoch 5, training accuracy 0.802326\n",
      "Epoch 6, training accuracy 0.802326\n",
      "Epoch 7, training accuracy 0.790698\n",
      "Epoch 8, training accuracy 0.802326\n",
      "Epoch 9, training accuracy 0.790698\n",
      "Epoch 10, training accuracy 0.790698\n",
      "Epoch 11, training accuracy 0.813953\n",
      "Epoch 12, training accuracy 0.813953\n",
      "Epoch 13, training accuracy 0.813953\n",
      "Epoch 14, training accuracy 0.813953\n",
      "Epoch 15, training accuracy 0.825581\n",
      "Epoch 16, training accuracy 0.813953\n",
      "Epoch 17, training accuracy 0.813953\n",
      "Epoch 18, training accuracy 0.813953\n",
      "Epoch 19, training accuracy 0.813953\n",
      "Epoch 20, training accuracy 0.825581\n",
      "Epoch 21, training accuracy 0.837209\n",
      "Epoch 22, training accuracy 0.848837\n",
      "Epoch 23, training accuracy 0.813953\n",
      "Epoch 24, training accuracy 0.860465\n",
      "Epoch 25, training accuracy 0.860465\n",
      "Epoch 26, training accuracy 0.837209\n",
      "Epoch 27, training accuracy 0.872093\n",
      "Epoch 28, training accuracy 0.860465\n",
      "Epoch 29, training accuracy 0.872093\n",
      "Epoch 30, training accuracy 0.872093\n",
      "Epoch 31, training accuracy 0.872093\n",
      "Epoch 32, training accuracy 0.883721\n",
      "Epoch 33, training accuracy 0.883721\n",
      "Epoch 34, training accuracy 0.895349\n",
      "Epoch 35, training accuracy 0.918605\n",
      "Epoch 36, training accuracy 0.883721\n",
      "Epoch 37, training accuracy 0.883721\n",
      "Epoch 38, training accuracy 0.930233\n",
      "Epoch 39, training accuracy 0.883721\n",
      "Epoch 40, training accuracy 0.918605\n",
      "Epoch 41, training accuracy 0.918605\n",
      "Epoch 42, training accuracy 0.918605\n",
      "Epoch 43, training accuracy 0.930233\n",
      "Epoch 44, training accuracy 0.918605\n",
      "Epoch 45, training accuracy 0.930233\n",
      "Epoch 46, training accuracy 0.930233\n",
      "Epoch 47, training accuracy 0.94186\n",
      "Epoch 48, training accuracy 0.94186\n",
      "Epoch 49, training accuracy 0.94186\n",
      "Epoch 50, training accuracy 0.930233\n",
      "Overall accuracy: 0.820895 \n",
      "\n",
      " \n",
      " Added new category: bee balm\n",
      "-------------Training new task: 8--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.877358\n",
      "Epoch 2, training accuracy 0.858491\n",
      "Epoch 3, training accuracy 0.877358\n",
      "Epoch 4, training accuracy 0.820755\n",
      "Epoch 5, training accuracy 0.839623\n",
      "Epoch 6, training accuracy 0.877358\n",
      "Epoch 7, training accuracy 0.867925\n",
      "Epoch 8, training accuracy 0.877358\n",
      "Epoch 9, training accuracy 0.867925\n",
      "Epoch 10, training accuracy 0.849057\n",
      "Epoch 11, training accuracy 0.877358\n",
      "Epoch 12, training accuracy 0.858491\n",
      "Epoch 13, training accuracy 0.858491\n",
      "Epoch 14, training accuracy 0.877358\n",
      "Epoch 15, training accuracy 0.867925\n",
      "Epoch 16, training accuracy 0.858491\n",
      "Epoch 17, training accuracy 0.867925\n",
      "Epoch 18, training accuracy 0.877358\n",
      "Epoch 19, training accuracy 0.877358\n",
      "Epoch 20, training accuracy 0.858491\n",
      "Epoch 21, training accuracy 0.867925\n",
      "Epoch 22, training accuracy 0.858491\n",
      "Epoch 23, training accuracy 0.858491\n",
      "Epoch 24, training accuracy 0.877358\n",
      "Epoch 25, training accuracy 0.858491\n",
      "Epoch 26, training accuracy 0.877358\n",
      "Epoch 27, training accuracy 0.877358\n",
      "Epoch 28, training accuracy 0.858491\n",
      "Epoch 29, training accuracy 0.858491\n",
      "Epoch 30, training accuracy 0.877358\n",
      "Epoch 31, training accuracy 0.858491\n",
      "Epoch 32, training accuracy 0.867925\n",
      "Epoch 33, training accuracy 0.877358\n",
      "Epoch 34, training accuracy 0.858491\n",
      "Epoch 35, training accuracy 0.858491\n",
      "Epoch 36, training accuracy 0.867925\n",
      "Epoch 37, training accuracy 0.849057\n",
      "Epoch 38, training accuracy 0.877358\n",
      "Epoch 39, training accuracy 0.858491\n",
      "Epoch 40, training accuracy 0.858491\n",
      "Epoch 41, training accuracy 0.858491\n",
      "Epoch 42, training accuracy 0.877358\n",
      "Epoch 43, training accuracy 0.858491\n",
      "Epoch 44, training accuracy 0.886792\n",
      "Epoch 45, training accuracy 0.858491\n",
      "Epoch 46, training accuracy 0.867925\n",
      "Epoch 47, training accuracy 0.877358\n",
      "Epoch 48, training accuracy 0.858491\n",
      "Epoch 49, training accuracy 0.877358\n",
      "Epoch 50, training accuracy 0.858491\n",
      "Overall accuracy: 0.615385 \n",
      "\n",
      " \n",
      " Added new category: bird of paradise\n",
      "-------------Training new task: 9--------------\n",
      "-----------Started Selective Retraining-------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.607143\n",
      "Epoch 2, training accuracy 0.692857\n",
      "Epoch 3, training accuracy 0.714286\n",
      "Epoch 4, training accuracy 0.728571\n",
      "Epoch 5, training accuracy 0.75\n",
      "Epoch 6, training accuracy 0.792857\n",
      "Epoch 7, training accuracy 0.8\n",
      "Epoch 8, training accuracy 0.828571\n",
      "Epoch 9, training accuracy 0.814286\n",
      "Epoch 10, training accuracy 0.842857\n",
      "Epoch 11, training accuracy 0.842857\n",
      "Epoch 12, training accuracy 0.842857\n",
      "Epoch 13, training accuracy 0.857143\n",
      "Epoch 14, training accuracy 0.857143\n",
      "Epoch 15, training accuracy 0.85\n",
      "Epoch 16, training accuracy 0.85\n",
      "Epoch 17, training accuracy 0.85\n",
      "Epoch 18, training accuracy 0.857143\n",
      "Epoch 19, training accuracy 0.842857\n",
      "Epoch 20, training accuracy 0.85\n",
      "Epoch 21, training accuracy 0.85\n",
      "Epoch 22, training accuracy 0.828571\n",
      "Epoch 23, training accuracy 0.85\n",
      "Epoch 24, training accuracy 0.85\n",
      "Epoch 25, training accuracy 0.842857\n",
      "Epoch 26, training accuracy 0.85\n",
      "Epoch 27, training accuracy 0.85\n",
      "Epoch 28, training accuracy 0.85\n",
      "Epoch 29, training accuracy 0.857143\n",
      "Epoch 30, training accuracy 0.857143\n",
      "Epoch 31, training accuracy 0.857143\n",
      "Epoch 32, training accuracy 0.857143\n",
      "Epoch 33, training accuracy 0.857143\n",
      "Epoch 34, training accuracy 0.857143\n",
      "Epoch 35, training accuracy 0.842857\n",
      "Epoch 36, training accuracy 0.857143\n",
      "Epoch 37, training accuracy 0.864286\n",
      "Epoch 38, training accuracy 0.864286\n",
      "Epoch 39, training accuracy 0.864286\n",
      "Epoch 40, training accuracy 0.864286\n",
      "Epoch 41, training accuracy 0.864286\n",
      "Epoch 42, training accuracy 0.864286\n",
      "Epoch 43, training accuracy 0.864286\n",
      "Epoch 44, training accuracy 0.878571\n",
      "Epoch 45, training accuracy 0.85\n",
      "Epoch 46, training accuracy 0.871429\n",
      "Epoch 47, training accuracy 0.864286\n",
      "Epoch 48, training accuracy 0.864286\n",
      "Epoch 49, training accuracy 0.864286\n",
      "Epoch 50, training accuracy 0.864286\n",
      "Overall accuracy: 0.613636 \n",
      "\n",
      " \n",
      " Added new category: bishop of llandaff\n",
      "-------------Training new task: 10--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.701087\n",
      "Epoch 2, training accuracy 0.701087\n",
      "Epoch 3, training accuracy 0.722826\n",
      "Epoch 4, training accuracy 0.733696\n",
      "Epoch 5, training accuracy 0.728261\n",
      "Epoch 6, training accuracy 0.728261\n",
      "Epoch 7, training accuracy 0.728261\n",
      "Epoch 8, training accuracy 0.733696\n",
      "Epoch 9, training accuracy 0.717391\n",
      "Epoch 10, training accuracy 0.75\n",
      "Epoch 11, training accuracy 0.76087\n",
      "Epoch 12, training accuracy 0.755435\n",
      "Epoch 13, training accuracy 0.76087\n",
      "Epoch 14, training accuracy 0.76087\n",
      "Epoch 15, training accuracy 0.755435\n",
      "Epoch 16, training accuracy 0.755435\n",
      "Epoch 17, training accuracy 0.744565\n",
      "Epoch 18, training accuracy 0.771739\n",
      "Epoch 19, training accuracy 0.771739\n",
      "Epoch 20, training accuracy 0.777174\n",
      "Epoch 21, training accuracy 0.782609\n",
      "Epoch 22, training accuracy 0.788043\n",
      "Epoch 23, training accuracy 0.804348\n",
      "Epoch 24, training accuracy 0.793478\n",
      "Epoch 25, training accuracy 0.793478\n",
      "Epoch 26, training accuracy 0.793478\n",
      "Epoch 27, training accuracy 0.809783\n",
      "Epoch 28, training accuracy 0.820652\n",
      "Epoch 29, training accuracy 0.815217\n",
      "Epoch 30, training accuracy 0.782609\n",
      "Epoch 31, training accuracy 0.809783\n",
      "Epoch 32, training accuracy 0.836957\n",
      "Epoch 33, training accuracy 0.831522\n",
      "Epoch 34, training accuracy 0.836957\n",
      "Epoch 35, training accuracy 0.853261\n",
      "Epoch 36, training accuracy 0.831522\n",
      "Epoch 37, training accuracy 0.842391\n",
      "Epoch 38, training accuracy 0.847826\n",
      "Epoch 39, training accuracy 0.847826\n",
      "Epoch 40, training accuracy 0.853261\n",
      "Epoch 41, training accuracy 0.853261\n",
      "Epoch 42, training accuracy 0.869565\n",
      "Epoch 43, training accuracy 0.869565\n",
      "Epoch 44, training accuracy 0.875\n",
      "Epoch 45, training accuracy 0.880435\n",
      "Epoch 46, training accuracy 0.875\n",
      "Epoch 47, training accuracy 0.880435\n",
      "Epoch 48, training accuracy 0.875\n",
      "Epoch 49, training accuracy 0.880435\n",
      "Epoch 50, training accuracy 0.86413\n",
      "Overall accuracy: 0.729167 \n",
      "\n",
      " \n",
      " Added new category: black-eyed susan\n",
      "-------------Training new task: 11--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.297619\n",
      "Epoch 2, training accuracy 0.321429\n",
      "Epoch 3, training accuracy 0.333333\n",
      "Epoch 4, training accuracy 0.333333\n",
      "Epoch 5, training accuracy 0.345238\n",
      "Epoch 6, training accuracy 0.321429\n",
      "Epoch 7, training accuracy 0.333333\n",
      "Epoch 8, training accuracy 0.333333\n",
      "Epoch 9, training accuracy 0.333333\n",
      "Epoch 10, training accuracy 0.333333\n",
      "Epoch 11, training accuracy 0.345238\n",
      "Epoch 12, training accuracy 0.333333\n",
      "Epoch 13, training accuracy 0.345238\n",
      "Epoch 14, training accuracy 0.357143\n",
      "Epoch 15, training accuracy 0.357143\n",
      "Epoch 16, training accuracy 0.345238\n",
      "Epoch 17, training accuracy 0.357143\n",
      "Epoch 18, training accuracy 0.357143\n",
      "Epoch 19, training accuracy 0.357143\n",
      "Epoch 20, training accuracy 0.357143\n",
      "Epoch 21, training accuracy 0.357143\n",
      "Epoch 22, training accuracy 0.369048\n",
      "Epoch 23, training accuracy 0.380952\n",
      "Epoch 24, training accuracy 0.380952\n",
      "Epoch 25, training accuracy 0.380952\n",
      "Epoch 26, training accuracy 0.404762\n",
      "Epoch 27, training accuracy 0.392857\n",
      "Epoch 28, training accuracy 0.392857\n",
      "Epoch 29, training accuracy 0.404762\n",
      "Epoch 30, training accuracy 0.392857\n",
      "Epoch 31, training accuracy 0.392857\n",
      "Epoch 32, training accuracy 0.404762\n",
      "Epoch 33, training accuracy 0.404762\n",
      "Epoch 34, training accuracy 0.416667\n",
      "Epoch 35, training accuracy 0.428571\n",
      "Epoch 36, training accuracy 0.428571\n",
      "Epoch 37, training accuracy 0.428571\n",
      "Epoch 38, training accuracy 0.47619\n",
      "Epoch 39, training accuracy 0.47619\n",
      "Epoch 40, training accuracy 0.5\n",
      "Epoch 41, training accuracy 0.547619\n",
      "Epoch 42, training accuracy 0.654762\n",
      "Epoch 43, training accuracy 0.690476\n",
      "Epoch 44, training accuracy 0.809524\n",
      "Epoch 45, training accuracy 0.821429\n",
      "Epoch 46, training accuracy 0.809524\n",
      "Epoch 47, training accuracy 0.821429\n",
      "Epoch 48, training accuracy 0.809524\n",
      "Epoch 49, training accuracy 0.797619\n",
      "Epoch 50, training accuracy 0.821429\n",
      "Overall accuracy: 0.51 \n",
      "\n",
      " \n",
      " Added new category: blackberry lily\n",
      "-------------Training new task: 12--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.791667\n",
      "Epoch 2, training accuracy 0.833333\n",
      "Epoch 3, training accuracy 0.805556\n",
      "Epoch 4, training accuracy 0.819444\n",
      "Epoch 5, training accuracy 0.791667\n",
      "Epoch 6, training accuracy 0.736111\n",
      "Epoch 7, training accuracy 0.777778\n",
      "Epoch 8, training accuracy 0.777778\n",
      "Epoch 9, training accuracy 0.777778\n",
      "Epoch 10, training accuracy 0.805556\n",
      "Epoch 11, training accuracy 0.791667\n",
      "Epoch 12, training accuracy 0.791667\n",
      "Epoch 13, training accuracy 0.791667\n",
      "Epoch 14, training accuracy 0.791667\n",
      "Epoch 15, training accuracy 0.791667\n",
      "Epoch 16, training accuracy 0.791667\n",
      "Epoch 17, training accuracy 0.791667\n",
      "Epoch 18, training accuracy 0.791667\n",
      "Epoch 19, training accuracy 0.791667\n",
      "Epoch 20, training accuracy 0.791667\n",
      "Epoch 21, training accuracy 0.791667\n",
      "Epoch 22, training accuracy 0.791667\n",
      "Epoch 23, training accuracy 0.791667\n",
      "Epoch 24, training accuracy 0.791667\n",
      "Epoch 25, training accuracy 0.791667\n",
      "Epoch 26, training accuracy 0.791667\n",
      "Epoch 27, training accuracy 0.791667\n",
      "Epoch 28, training accuracy 0.805556\n",
      "Epoch 29, training accuracy 0.791667\n",
      "Epoch 30, training accuracy 0.805556\n",
      "Epoch 31, training accuracy 0.805556\n",
      "Epoch 32, training accuracy 0.805556\n",
      "Epoch 33, training accuracy 0.805556\n",
      "Epoch 34, training accuracy 0.805556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, training accuracy 0.805556\n",
      "Epoch 36, training accuracy 0.805556\n",
      "Epoch 37, training accuracy 0.805556\n",
      "Epoch 38, training accuracy 0.805556\n",
      "Epoch 39, training accuracy 0.805556\n",
      "Epoch 40, training accuracy 0.805556\n",
      "Epoch 41, training accuracy 0.805556\n",
      "Epoch 42, training accuracy 0.805556\n",
      "Epoch 43, training accuracy 0.805556\n",
      "Epoch 44, training accuracy 0.805556\n",
      "Epoch 45, training accuracy 0.805556\n",
      "Epoch 46, training accuracy 0.805556\n",
      "Epoch 47, training accuracy 0.805556\n",
      "Epoch 48, training accuracy 0.805556\n",
      "Epoch 49, training accuracy 0.805556\n",
      "Epoch 50, training accuracy 0.805556\n",
      "Overall accuracy: 0.45283 \n",
      "\n",
      " \n",
      " Added new category: blanket flower\n",
      "-------------Training new task: 13--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.6\n",
      "Epoch 2, training accuracy 0.671429\n",
      "Epoch 3, training accuracy 0.685714\n",
      "Epoch 4, training accuracy 0.714286\n",
      "Epoch 5, training accuracy 0.728571\n",
      "Epoch 6, training accuracy 0.757143\n",
      "Epoch 7, training accuracy 0.842857\n",
      "Epoch 8, training accuracy 0.842857\n",
      "Epoch 9, training accuracy 0.842857\n",
      "Epoch 10, training accuracy 0.885714\n",
      "Epoch 11, training accuracy 0.857143\n",
      "Epoch 12, training accuracy 0.842857\n",
      "Epoch 13, training accuracy 0.842857\n",
      "Epoch 14, training accuracy 0.871429\n",
      "Epoch 15, training accuracy 0.871429\n",
      "Epoch 16, training accuracy 0.871429\n",
      "Epoch 17, training accuracy 0.885714\n",
      "Epoch 18, training accuracy 0.871429\n",
      "Epoch 19, training accuracy 0.885714\n",
      "Epoch 20, training accuracy 0.871429\n",
      "Epoch 21, training accuracy 0.871429\n",
      "Epoch 22, training accuracy 0.871429\n",
      "Epoch 23, training accuracy 0.885714\n",
      "Epoch 24, training accuracy 0.885714\n",
      "Epoch 25, training accuracy 0.885714\n",
      "Epoch 26, training accuracy 0.885714\n",
      "Epoch 27, training accuracy 0.885714\n",
      "Epoch 28, training accuracy 0.885714\n",
      "Epoch 29, training accuracy 0.885714\n",
      "Epoch 30, training accuracy 0.885714\n",
      "Epoch 31, training accuracy 0.885714\n",
      "Epoch 32, training accuracy 0.871429\n",
      "Epoch 33, training accuracy 0.885714\n",
      "Epoch 34, training accuracy 0.885714\n",
      "Epoch 35, training accuracy 0.885714\n",
      "Epoch 36, training accuracy 0.885714\n",
      "Epoch 37, training accuracy 0.885714\n",
      "Epoch 38, training accuracy 0.885714\n",
      "Epoch 39, training accuracy 0.885714\n",
      "Epoch 40, training accuracy 0.885714\n",
      "Epoch 41, training accuracy 0.885714\n",
      "Epoch 42, training accuracy 0.871429\n",
      "Epoch 43, training accuracy 0.871429\n",
      "Epoch 44, training accuracy 0.871429\n",
      "Epoch 45, training accuracy 0.871429\n",
      "Epoch 46, training accuracy 0.871429\n",
      "Epoch 47, training accuracy 0.871429\n",
      "Epoch 48, training accuracy 0.857143\n",
      "Epoch 49, training accuracy 0.871429\n",
      "Epoch 50, training accuracy 0.871429\n",
      "Overall accuracy: 0.464912 \n",
      "\n",
      " \n",
      " Added new category: bolero deep blue\n",
      "-------------Training new task: 14--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.636364\n",
      "Epoch 2, training accuracy 0.651515\n",
      "Epoch 3, training accuracy 0.651515\n",
      "Epoch 4, training accuracy 0.651515\n",
      "Epoch 5, training accuracy 0.636364\n",
      "Epoch 6, training accuracy 0.636364\n",
      "Epoch 7, training accuracy 0.636364\n",
      "Epoch 8, training accuracy 0.636364\n",
      "Epoch 9, training accuracy 0.651515\n",
      "Epoch 10, training accuracy 0.636364\n",
      "Epoch 11, training accuracy 0.636364\n",
      "Epoch 12, training accuracy 0.636364\n",
      "Epoch 13, training accuracy 0.651515\n",
      "Epoch 14, training accuracy 0.606061\n",
      "Epoch 15, training accuracy 0.621212\n",
      "Epoch 16, training accuracy 0.651515\n",
      "Epoch 17, training accuracy 0.606061\n",
      "Epoch 18, training accuracy 0.621212\n",
      "Epoch 19, training accuracy 0.651515\n",
      "Epoch 20, training accuracy 0.636364\n",
      "Epoch 21, training accuracy 0.621212\n",
      "Epoch 22, training accuracy 0.636364\n",
      "Epoch 23, training accuracy 0.651515\n",
      "Epoch 24, training accuracy 0.636364\n",
      "Epoch 25, training accuracy 0.651515\n",
      "Epoch 26, training accuracy 0.651515\n",
      "Epoch 27, training accuracy 0.636364\n",
      "Epoch 28, training accuracy 0.636364\n",
      "Epoch 29, training accuracy 0.636364\n",
      "Epoch 30, training accuracy 0.681818\n",
      "Epoch 31, training accuracy 0.666667\n",
      "Epoch 32, training accuracy 0.666667\n",
      "Epoch 33, training accuracy 0.651515\n",
      "Epoch 34, training accuracy 0.666667\n",
      "Epoch 35, training accuracy 0.666667\n",
      "Epoch 36, training accuracy 0.681818\n",
      "Epoch 37, training accuracy 0.666667\n",
      "Epoch 38, training accuracy 0.666667\n",
      "Epoch 39, training accuracy 0.69697\n",
      "Epoch 40, training accuracy 0.69697\n",
      "Epoch 41, training accuracy 0.69697\n",
      "Epoch 42, training accuracy 0.69697\n",
      "Epoch 43, training accuracy 0.69697\n",
      "Epoch 44, training accuracy 0.69697\n",
      "Epoch 45, training accuracy 0.69697\n",
      "Epoch 46, training accuracy 0.69697\n",
      "Epoch 47, training accuracy 0.681818\n",
      "Epoch 48, training accuracy 0.69697\n",
      "Epoch 49, training accuracy 0.681818\n",
      "Epoch 50, training accuracy 0.69697\n",
      "Overall accuracy: 0.384615 \n",
      "\n",
      " \n",
      " Added new category: bougainvillea\n",
      "-------------Training new task: 15--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.668317\n",
      "Epoch 2, training accuracy 0.638614\n",
      "Epoch 3, training accuracy 0.683168\n",
      "Epoch 4, training accuracy 0.683168\n",
      "Epoch 5, training accuracy 0.678218\n",
      "Epoch 6, training accuracy 0.688119\n",
      "Epoch 7, training accuracy 0.693069\n",
      "Epoch 8, training accuracy 0.717822\n",
      "Epoch 9, training accuracy 0.727723\n",
      "Epoch 10, training accuracy 0.737624\n",
      "Epoch 11, training accuracy 0.727723\n",
      "Epoch 12, training accuracy 0.757426\n",
      "Epoch 13, training accuracy 0.762376\n",
      "Epoch 14, training accuracy 0.777228\n",
      "Epoch 15, training accuracy 0.772277\n",
      "Epoch 16, training accuracy 0.772277\n",
      "Epoch 17, training accuracy 0.767327\n",
      "Epoch 18, training accuracy 0.782178\n",
      "Epoch 19, training accuracy 0.782178\n",
      "Epoch 20, training accuracy 0.777228\n",
      "Epoch 21, training accuracy 0.792079\n",
      "Epoch 22, training accuracy 0.782178\n",
      "Epoch 23, training accuracy 0.782178\n",
      "Epoch 24, training accuracy 0.787129\n",
      "Epoch 25, training accuracy 0.787129\n",
      "Epoch 26, training accuracy 0.787129\n",
      "Epoch 27, training accuracy 0.787129\n",
      "Epoch 28, training accuracy 0.787129\n",
      "Epoch 29, training accuracy 0.782178\n",
      "Epoch 30, training accuracy 0.772277\n",
      "Epoch 31, training accuracy 0.787129\n",
      "Epoch 32, training accuracy 0.787129\n",
      "Epoch 33, training accuracy 0.782178\n",
      "Epoch 34, training accuracy 0.782178\n",
      "Epoch 35, training accuracy 0.792079\n",
      "Epoch 36, training accuracy 0.782178\n",
      "Epoch 37, training accuracy 0.782178\n",
      "Epoch 38, training accuracy 0.792079\n",
      "Epoch 39, training accuracy 0.792079\n",
      "Epoch 40, training accuracy 0.792079\n",
      "Epoch 41, training accuracy 0.782178\n",
      "Epoch 42, training accuracy 0.787129\n",
      "Epoch 43, training accuracy 0.782178\n",
      "Epoch 44, training accuracy 0.787129\n",
      "Epoch 45, training accuracy 0.787129\n",
      "Epoch 46, training accuracy 0.787129\n",
      "Epoch 47, training accuracy 0.79703\n",
      "Epoch 48, training accuracy 0.782178\n",
      "Epoch 49, training accuracy 0.787129\n",
      "Epoch 50, training accuracy 0.787129\n",
      "Overall accuracy: 0.480916 \n",
      "\n",
      " \n",
      " Added new category: bromelia\n",
      "-------------Training new task: 16--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.56\n",
      "Epoch 2, training accuracy 0.56\n",
      "Epoch 3, training accuracy 0.58\n",
      "Epoch 4, training accuracy 0.58\n",
      "Epoch 5, training accuracy 0.59\n",
      "Epoch 6, training accuracy 0.59\n",
      "Epoch 7, training accuracy 0.63\n",
      "Epoch 8, training accuracy 0.62\n",
      "Epoch 9, training accuracy 0.65\n",
      "Epoch 10, training accuracy 0.65\n",
      "Epoch 11, training accuracy 0.65\n",
      "Epoch 12, training accuracy 0.66\n",
      "Epoch 13, training accuracy 0.65\n",
      "Epoch 14, training accuracy 0.65\n",
      "Epoch 15, training accuracy 0.65\n",
      "Epoch 16, training accuracy 0.68\n",
      "Epoch 17, training accuracy 0.65\n",
      "Epoch 18, training accuracy 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, training accuracy 0.67\n",
      "Epoch 20, training accuracy 0.69\n",
      "Epoch 21, training accuracy 0.68\n",
      "Epoch 22, training accuracy 0.67\n",
      "Epoch 23, training accuracy 0.69\n",
      "Epoch 24, training accuracy 0.68\n",
      "Epoch 25, training accuracy 0.69\n",
      "Epoch 26, training accuracy 0.69\n",
      "Epoch 27, training accuracy 0.68\n",
      "Epoch 28, training accuracy 0.69\n",
      "Epoch 29, training accuracy 0.7\n",
      "Epoch 30, training accuracy 0.66\n",
      "Epoch 31, training accuracy 0.7\n",
      "Epoch 32, training accuracy 0.65\n",
      "Epoch 33, training accuracy 0.7\n",
      "Epoch 34, training accuracy 0.71\n",
      "Epoch 35, training accuracy 0.69\n",
      "Epoch 36, training accuracy 0.71\n",
      "Epoch 37, training accuracy 0.68\n",
      "Epoch 38, training accuracy 0.72\n",
      "Epoch 39, training accuracy 0.68\n",
      "Epoch 40, training accuracy 0.71\n",
      "Epoch 41, training accuracy 0.7\n",
      "Epoch 42, training accuracy 0.71\n",
      "Epoch 43, training accuracy 0.71\n",
      "Epoch 44, training accuracy 0.71\n",
      "Epoch 45, training accuracy 0.72\n",
      "Epoch 46, training accuracy 0.72\n",
      "Epoch 47, training accuracy 0.73\n",
      "Epoch 48, training accuracy 0.74\n",
      "Epoch 49, training accuracy 0.73\n",
      "Epoch 50, training accuracy 0.74\n",
      "Overall accuracy: 0.326087 \n",
      "\n",
      " \n",
      " Added new category: buttercup\n",
      "-------------Training new task: 17--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.508772\n",
      "Epoch 2, training accuracy 0.578947\n",
      "Epoch 3, training accuracy 0.587719\n",
      "Epoch 4, training accuracy 0.614035\n",
      "Epoch 5, training accuracy 0.631579\n",
      "Epoch 6, training accuracy 0.622807\n",
      "Epoch 7, training accuracy 0.657895\n",
      "Epoch 8, training accuracy 0.631579\n",
      "Epoch 9, training accuracy 0.675439\n",
      "Epoch 10, training accuracy 0.692982\n",
      "Epoch 11, training accuracy 0.692982\n",
      "Epoch 12, training accuracy 0.692982\n",
      "Epoch 13, training accuracy 0.710526\n",
      "Epoch 14, training accuracy 0.710526\n",
      "Epoch 15, training accuracy 0.710526\n",
      "Epoch 16, training accuracy 0.72807\n",
      "Epoch 17, training accuracy 0.719298\n",
      "Epoch 18, training accuracy 0.72807\n",
      "Epoch 19, training accuracy 0.72807\n",
      "Epoch 20, training accuracy 0.745614\n",
      "Epoch 21, training accuracy 0.745614\n",
      "Epoch 22, training accuracy 0.745614\n",
      "Epoch 23, training accuracy 0.754386\n",
      "Epoch 24, training accuracy 0.745614\n",
      "Epoch 25, training accuracy 0.736842\n",
      "Epoch 26, training accuracy 0.72807\n",
      "Epoch 27, training accuracy 0.736842\n",
      "Epoch 28, training accuracy 0.72807\n",
      "Epoch 29, training accuracy 0.72807\n",
      "Epoch 30, training accuracy 0.72807\n",
      "Epoch 31, training accuracy 0.72807\n",
      "Epoch 32, training accuracy 0.736842\n",
      "Epoch 33, training accuracy 0.736842\n",
      "Epoch 34, training accuracy 0.736842\n",
      "Epoch 35, training accuracy 0.763158\n",
      "Epoch 36, training accuracy 0.745614\n",
      "Epoch 37, training accuracy 0.72807\n",
      "Epoch 38, training accuracy 0.745614\n",
      "Epoch 39, training accuracy 0.736842\n",
      "Epoch 40, training accuracy 0.72807\n",
      "Epoch 41, training accuracy 0.72807\n",
      "Epoch 42, training accuracy 0.763158\n",
      "Epoch 43, training accuracy 0.72807\n",
      "Epoch 44, training accuracy 0.754386\n",
      "Epoch 45, training accuracy 0.719298\n",
      "Epoch 46, training accuracy 0.72807\n",
      "Epoch 47, training accuracy 0.77193\n",
      "Epoch 48, training accuracy 0.72807\n",
      "Epoch 49, training accuracy 0.72807\n",
      "Epoch 50, training accuracy 0.77193\n",
      "Overall accuracy: 0.370629 \n",
      "\n",
      " \n",
      " Added new category: californian poppy\n",
      "-------------Training new task: 18--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.551136\n",
      "Epoch 2, training accuracy 0.590909\n",
      "Epoch 3, training accuracy 0.602273\n",
      "Epoch 4, training accuracy 0.619318\n",
      "Epoch 5, training accuracy 0.636364\n",
      "Epoch 6, training accuracy 0.636364\n",
      "Epoch 7, training accuracy 0.647727\n",
      "Epoch 8, training accuracy 0.647727\n",
      "Epoch 9, training accuracy 0.642045\n",
      "Epoch 10, training accuracy 0.653409\n",
      "Epoch 11, training accuracy 0.659091\n",
      "Epoch 12, training accuracy 0.664773\n",
      "Epoch 13, training accuracy 0.647727\n",
      "Epoch 14, training accuracy 0.642045\n",
      "Epoch 15, training accuracy 0.653409\n",
      "Epoch 16, training accuracy 0.6875\n",
      "Epoch 17, training accuracy 0.681818\n",
      "Epoch 18, training accuracy 0.681818\n",
      "Epoch 19, training accuracy 0.6875\n",
      "Epoch 20, training accuracy 0.704545\n",
      "Epoch 21, training accuracy 0.664773\n",
      "Epoch 22, training accuracy 0.704545\n",
      "Epoch 23, training accuracy 0.6875\n",
      "Epoch 24, training accuracy 0.698864\n",
      "Epoch 25, training accuracy 0.698864\n",
      "Epoch 26, training accuracy 0.698864\n",
      "Epoch 27, training accuracy 0.693182\n",
      "Epoch 28, training accuracy 0.698864\n",
      "Epoch 29, training accuracy 0.710227\n",
      "Epoch 30, training accuracy 0.681818\n",
      "Epoch 31, training accuracy 0.693182\n",
      "Epoch 32, training accuracy 0.693182\n",
      "Epoch 33, training accuracy 0.681818\n",
      "Epoch 34, training accuracy 0.693182\n",
      "Epoch 35, training accuracy 0.698864\n",
      "Epoch 36, training accuracy 0.698864\n",
      "Epoch 37, training accuracy 0.698864\n",
      "Epoch 38, training accuracy 0.698864\n",
      "Epoch 39, training accuracy 0.698864\n",
      "Epoch 40, training accuracy 0.710227\n",
      "Epoch 41, training accuracy 0.710227\n",
      "Epoch 42, training accuracy 0.704545\n",
      "Epoch 43, training accuracy 0.698864\n",
      "Epoch 44, training accuracy 0.698864\n",
      "Epoch 45, training accuracy 0.710227\n",
      "Epoch 46, training accuracy 0.710227\n",
      "Epoch 47, training accuracy 0.710227\n",
      "Epoch 48, training accuracy 0.704545\n",
      "Epoch 49, training accuracy 0.704545\n",
      "Epoch 50, training accuracy 0.710227\n",
      "Overall accuracy: 0.426667 \n",
      "\n",
      " \n",
      " Added new category: camellia\n",
      "-------------Training new task: 19--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.611111\n",
      "Epoch 2, training accuracy 0.618056\n",
      "Epoch 3, training accuracy 0.611111\n",
      "Epoch 4, training accuracy 0.618056\n",
      "Epoch 5, training accuracy 0.631944\n",
      "Epoch 6, training accuracy 0.638889\n",
      "Epoch 7, training accuracy 0.652778\n",
      "Epoch 8, training accuracy 0.645833\n",
      "Epoch 9, training accuracy 0.666667\n",
      "Epoch 10, training accuracy 0.652778\n",
      "Epoch 11, training accuracy 0.673611\n",
      "Epoch 12, training accuracy 0.652778\n",
      "Epoch 13, training accuracy 0.652778\n",
      "Epoch 14, training accuracy 0.652778\n",
      "Epoch 15, training accuracy 0.652778\n",
      "Epoch 16, training accuracy 0.652778\n",
      "Epoch 17, training accuracy 0.652778\n",
      "Epoch 18, training accuracy 0.652778\n",
      "Epoch 19, training accuracy 0.652778\n",
      "Epoch 20, training accuracy 0.652778\n",
      "Epoch 21, training accuracy 0.652778\n",
      "Epoch 22, training accuracy 0.645833\n",
      "Epoch 23, training accuracy 0.652778\n",
      "Epoch 24, training accuracy 0.645833\n",
      "Epoch 25, training accuracy 0.659722\n",
      "Epoch 26, training accuracy 0.659722\n",
      "Epoch 27, training accuracy 0.645833\n",
      "Epoch 28, training accuracy 0.659722\n",
      "Epoch 29, training accuracy 0.659722\n",
      "Epoch 30, training accuracy 0.659722\n",
      "Epoch 31, training accuracy 0.659722\n",
      "Epoch 32, training accuracy 0.659722\n",
      "Epoch 33, training accuracy 0.659722\n",
      "Epoch 34, training accuracy 0.666667\n",
      "Epoch 35, training accuracy 0.659722\n",
      "Epoch 36, training accuracy 0.659722\n",
      "Epoch 37, training accuracy 0.659722\n",
      "Epoch 38, training accuracy 0.666667\n",
      "Epoch 39, training accuracy 0.659722\n",
      "Epoch 40, training accuracy 0.666667\n",
      "Epoch 41, training accuracy 0.666667\n",
      "Epoch 42, training accuracy 0.666667\n",
      "Epoch 43, training accuracy 0.666667\n",
      "Epoch 44, training accuracy 0.659722\n",
      "Epoch 45, training accuracy 0.652778\n",
      "Epoch 46, training accuracy 0.652778\n",
      "Epoch 47, training accuracy 0.666667\n",
      "Epoch 48, training accuracy 0.659722\n",
      "Epoch 49, training accuracy 0.666667\n",
      "Epoch 50, training accuracy 0.659722\n",
      "Overall accuracy: 0.264151 \n",
      "\n",
      " \n",
      " Added new category: canna lily\n",
      "-------------Training new task: 20--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training accuracy 0.55303\n",
      "Epoch 2, training accuracy 0.575758\n",
      "Epoch 3, training accuracy 0.590909\n",
      "Epoch 4, training accuracy 0.583333\n",
      "Epoch 5, training accuracy 0.583333\n",
      "Epoch 6, training accuracy 0.568182\n",
      "Epoch 7, training accuracy 0.583333\n",
      "Epoch 8, training accuracy 0.575758\n",
      "Epoch 9, training accuracy 0.575758\n",
      "Epoch 10, training accuracy 0.590909\n",
      "Epoch 11, training accuracy 0.590909\n",
      "Epoch 12, training accuracy 0.575758\n",
      "Epoch 13, training accuracy 0.606061\n",
      "Epoch 14, training accuracy 0.606061\n",
      "Epoch 15, training accuracy 0.590909\n",
      "Epoch 16, training accuracy 0.613636\n",
      "Epoch 17, training accuracy 0.613636\n",
      "Epoch 18, training accuracy 0.606061\n",
      "Epoch 19, training accuracy 0.636364\n",
      "Epoch 20, training accuracy 0.628788\n",
      "Epoch 21, training accuracy 0.613636\n",
      "Epoch 22, training accuracy 0.651515\n",
      "Epoch 23, training accuracy 0.636364\n",
      "Epoch 24, training accuracy 0.643939\n",
      "Epoch 25, training accuracy 0.606061\n",
      "Epoch 26, training accuracy 0.651515\n",
      "Epoch 27, training accuracy 0.636364\n",
      "Epoch 28, training accuracy 0.651515\n",
      "Epoch 29, training accuracy 0.613636\n",
      "Epoch 30, training accuracy 0.643939\n",
      "Epoch 31, training accuracy 0.636364\n",
      "Epoch 32, training accuracy 0.651515\n",
      "Epoch 33, training accuracy 0.643939\n",
      "Epoch 34, training accuracy 0.643939\n",
      "Epoch 35, training accuracy 0.643939\n",
      "Epoch 36, training accuracy 0.643939\n",
      "Epoch 37, training accuracy 0.643939\n",
      "Epoch 38, training accuracy 0.628788\n",
      "Epoch 39, training accuracy 0.651515\n",
      "Epoch 40, training accuracy 0.651515\n",
      "Epoch 41, training accuracy 0.651515\n",
      "Epoch 42, training accuracy 0.643939\n",
      "Epoch 43, training accuracy 0.643939\n",
      "Epoch 44, training accuracy 0.643939\n",
      "Epoch 45, training accuracy 0.636364\n",
      "Epoch 46, training accuracy 0.659091\n",
      "Epoch 47, training accuracy 0.643939\n",
      "Epoch 48, training accuracy 0.659091\n",
      "Epoch 49, training accuracy 0.636364\n",
      "Epoch 50, training accuracy 0.659091\n",
      "Overall accuracy: 0.410405 \n",
      "\n",
      " \n",
      " Added new category: canterbury bells\n",
      "-------------Training new task: 21--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.541667\n",
      "Epoch 2, training accuracy 0.583333\n",
      "Epoch 3, training accuracy 0.583333\n",
      "Epoch 4, training accuracy 0.583333\n",
      "Epoch 5, training accuracy 0.583333\n",
      "Epoch 6, training accuracy 0.597222\n",
      "Epoch 7, training accuracy 0.597222\n",
      "Epoch 8, training accuracy 0.597222\n",
      "Epoch 9, training accuracy 0.597222\n",
      "Epoch 10, training accuracy 0.611111\n",
      "Epoch 11, training accuracy 0.611111\n",
      "Epoch 12, training accuracy 0.611111\n",
      "Epoch 13, training accuracy 0.611111\n",
      "Epoch 14, training accuracy 0.611111\n",
      "Epoch 15, training accuracy 0.625\n",
      "Epoch 16, training accuracy 0.611111\n",
      "Epoch 17, training accuracy 0.611111\n",
      "Epoch 18, training accuracy 0.611111\n",
      "Epoch 19, training accuracy 0.611111\n",
      "Epoch 20, training accuracy 0.611111\n",
      "Epoch 21, training accuracy 0.625\n",
      "Epoch 22, training accuracy 0.625\n",
      "Epoch 23, training accuracy 0.625\n",
      "Epoch 24, training accuracy 0.625\n",
      "Epoch 25, training accuracy 0.625\n",
      "Epoch 26, training accuracy 0.625\n",
      "Epoch 27, training accuracy 0.625\n",
      "Epoch 28, training accuracy 0.638889\n",
      "Epoch 29, training accuracy 0.638889\n",
      "Epoch 30, training accuracy 0.625\n",
      "Epoch 31, training accuracy 0.638889\n",
      "Epoch 32, training accuracy 0.638889\n",
      "Epoch 33, training accuracy 0.638889\n",
      "Epoch 34, training accuracy 0.638889\n",
      "Epoch 35, training accuracy 0.652778\n",
      "Epoch 36, training accuracy 0.652778\n",
      "Epoch 37, training accuracy 0.638889\n",
      "Epoch 38, training accuracy 0.652778\n",
      "Epoch 39, training accuracy 0.652778\n",
      "Epoch 40, training accuracy 0.666667\n",
      "Epoch 41, training accuracy 0.652778\n",
      "Epoch 42, training accuracy 0.666667\n",
      "Epoch 43, training accuracy 0.666667\n",
      "Epoch 44, training accuracy 0.666667\n",
      "Epoch 45, training accuracy 0.666667\n",
      "Epoch 46, training accuracy 0.666667\n",
      "Epoch 47, training accuracy 0.666667\n",
      "Epoch 48, training accuracy 0.666667\n",
      "Epoch 49, training accuracy 0.680556\n",
      "Epoch 50, training accuracy 0.666667\n",
      "Overall accuracy: 0.262857 \n",
      "\n",
      " \n",
      " Added new category: cape flower\n",
      "-------------Training new task: 22--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.347826\n",
      "Epoch 2, training accuracy 0.48913\n",
      "Epoch 3, training accuracy 0.407609\n",
      "Epoch 4, training accuracy 0.483696\n",
      "Epoch 5, training accuracy 0.467391\n",
      "Epoch 6, training accuracy 0.472826\n",
      "Epoch 7, training accuracy 0.494565\n",
      "Epoch 8, training accuracy 0.483696\n",
      "Epoch 9, training accuracy 0.527174\n",
      "Epoch 10, training accuracy 0.521739\n",
      "Epoch 11, training accuracy 0.516304\n",
      "Epoch 12, training accuracy 0.478261\n",
      "Epoch 13, training accuracy 0.559783\n",
      "Epoch 14, training accuracy 0.625\n",
      "Epoch 15, training accuracy 0.63587\n",
      "Epoch 16, training accuracy 0.630435\n",
      "Epoch 17, training accuracy 0.646739\n",
      "Epoch 18, training accuracy 0.630435\n",
      "Epoch 19, training accuracy 0.63587\n",
      "Epoch 20, training accuracy 0.641304\n",
      "Epoch 21, training accuracy 0.603261\n",
      "Epoch 22, training accuracy 0.641304\n",
      "Epoch 23, training accuracy 0.619565\n",
      "Epoch 24, training accuracy 0.641304\n",
      "Epoch 25, training accuracy 0.652174\n",
      "Epoch 26, training accuracy 0.625\n",
      "Epoch 27, training accuracy 0.646739\n",
      "Epoch 28, training accuracy 0.625\n",
      "Epoch 29, training accuracy 0.641304\n",
      "Epoch 30, training accuracy 0.625\n",
      "Epoch 31, training accuracy 0.668478\n",
      "Epoch 32, training accuracy 0.663043\n",
      "Epoch 33, training accuracy 0.63587\n",
      "Epoch 34, training accuracy 0.63587\n",
      "Epoch 35, training accuracy 0.657609\n",
      "Epoch 36, training accuracy 0.646739\n",
      "Epoch 37, training accuracy 0.657609\n",
      "Epoch 38, training accuracy 0.630435\n",
      "Epoch 39, training accuracy 0.679348\n",
      "Epoch 40, training accuracy 0.641304\n",
      "Epoch 41, training accuracy 0.641304\n",
      "Epoch 42, training accuracy 0.630435\n",
      "Epoch 43, training accuracy 0.668478\n",
      "Epoch 44, training accuracy 0.619565\n",
      "Epoch 45, training accuracy 0.679348\n",
      "Epoch 46, training accuracy 0.646739\n",
      "Epoch 47, training accuracy 0.679348\n",
      "Epoch 48, training accuracy 0.63587\n",
      "Epoch 49, training accuracy 0.668478\n",
      "Epoch 50, training accuracy 0.663043\n",
      "Overall accuracy: 0.213115 \n",
      "\n",
      " \n",
      " Added new category: carnation\n",
      "-------------Training new task: 23--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.46875\n",
      "Epoch 2, training accuracy 0.46875\n",
      "Epoch 3, training accuracy 0.4375\n",
      "Epoch 4, training accuracy 0.46875\n",
      "Epoch 5, training accuracy 0.489583\n",
      "Epoch 6, training accuracy 0.489583\n",
      "Epoch 7, training accuracy 0.416667\n",
      "Epoch 8, training accuracy 0.5\n",
      "Epoch 9, training accuracy 0.510417\n",
      "Epoch 10, training accuracy 0.458333\n",
      "Epoch 11, training accuracy 0.458333\n",
      "Epoch 12, training accuracy 0.53125\n",
      "Epoch 13, training accuracy 0.510417\n",
      "Epoch 14, training accuracy 0.5\n",
      "Epoch 15, training accuracy 0.53125\n",
      "Epoch 16, training accuracy 0.552083\n",
      "Epoch 17, training accuracy 0.5625\n",
      "Epoch 18, training accuracy 0.552083\n",
      "Epoch 19, training accuracy 0.5625\n",
      "Epoch 20, training accuracy 0.5625\n",
      "Epoch 21, training accuracy 0.5625\n",
      "Epoch 22, training accuracy 0.572917\n",
      "Epoch 23, training accuracy 0.5625\n",
      "Epoch 24, training accuracy 0.59375\n",
      "Epoch 25, training accuracy 0.604167\n",
      "Epoch 26, training accuracy 0.604167\n",
      "Epoch 27, training accuracy 0.604167\n",
      "Epoch 28, training accuracy 0.604167\n",
      "Epoch 29, training accuracy 0.614583\n",
      "Epoch 30, training accuracy 0.614583\n",
      "Epoch 31, training accuracy 0.614583\n",
      "Epoch 32, training accuracy 0.614583\n",
      "Epoch 33, training accuracy 0.614583\n",
      "Epoch 34, training accuracy 0.614583\n",
      "Epoch 35, training accuracy 0.614583\n",
      "Epoch 36, training accuracy 0.614583\n",
      "Epoch 37, training accuracy 0.625\n",
      "Epoch 38, training accuracy 0.614583\n",
      "Epoch 39, training accuracy 0.625\n",
      "Epoch 40, training accuracy 0.614583\n",
      "Epoch 41, training accuracy 0.625\n",
      "Epoch 42, training accuracy 0.625\n",
      "Epoch 43, training accuracy 0.614583\n",
      "Epoch 44, training accuracy 0.635417\n",
      "Epoch 45, training accuracy 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, training accuracy 0.625\n",
      "Epoch 47, training accuracy 0.635417\n",
      "Epoch 48, training accuracy 0.635417\n",
      "Epoch 49, training accuracy 0.635417\n",
      "Epoch 50, training accuracy 0.635417\n",
      "Overall accuracy: 0.254054 \n",
      "\n",
      " \n",
      " Added new category: cautleya spicata\n",
      "-------------Training new task: 24--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.555556\n",
      "Epoch 2, training accuracy 0.527778\n",
      "Epoch 3, training accuracy 0.527778\n",
      "Epoch 4, training accuracy 0.555556\n",
      "Epoch 5, training accuracy 0.555556\n",
      "Epoch 6, training accuracy 0.541667\n",
      "Epoch 7, training accuracy 0.555556\n",
      "Epoch 8, training accuracy 0.555556\n",
      "Epoch 9, training accuracy 0.555556\n",
      "Epoch 10, training accuracy 0.555556\n",
      "Epoch 11, training accuracy 0.555556\n",
      "Epoch 12, training accuracy 0.555556\n",
      "Epoch 13, training accuracy 0.555556\n",
      "Epoch 14, training accuracy 0.555556\n",
      "Epoch 15, training accuracy 0.555556\n",
      "Epoch 16, training accuracy 0.569444\n",
      "Epoch 17, training accuracy 0.569444\n",
      "Epoch 18, training accuracy 0.569444\n",
      "Epoch 19, training accuracy 0.569444\n",
      "Epoch 20, training accuracy 0.569444\n",
      "Epoch 21, training accuracy 0.569444\n",
      "Epoch 22, training accuracy 0.569444\n",
      "Epoch 23, training accuracy 0.569444\n",
      "Epoch 24, training accuracy 0.569444\n",
      "Epoch 25, training accuracy 0.569444\n",
      "Epoch 26, training accuracy 0.569444\n",
      "Epoch 27, training accuracy 0.569444\n",
      "Epoch 28, training accuracy 0.569444\n",
      "Epoch 29, training accuracy 0.569444\n",
      "Epoch 30, training accuracy 0.569444\n",
      "Epoch 31, training accuracy 0.569444\n",
      "Epoch 32, training accuracy 0.569444\n",
      "Epoch 33, training accuracy 0.611111\n",
      "Epoch 34, training accuracy 0.625\n",
      "Epoch 35, training accuracy 0.611111\n",
      "Epoch 36, training accuracy 0.611111\n",
      "Epoch 37, training accuracy 0.638889\n",
      "Epoch 38, training accuracy 0.625\n",
      "Epoch 39, training accuracy 0.625\n",
      "Epoch 40, training accuracy 0.625\n",
      "Epoch 41, training accuracy 0.625\n",
      "Epoch 42, training accuracy 0.625\n",
      "Epoch 43, training accuracy 0.625\n",
      "Epoch 44, training accuracy 0.638889\n",
      "Epoch 45, training accuracy 0.638889\n",
      "Epoch 46, training accuracy 0.638889\n",
      "Epoch 47, training accuracy 0.638889\n",
      "Epoch 48, training accuracy 0.638889\n",
      "Epoch 49, training accuracy 0.638889\n",
      "Epoch 50, training accuracy 0.638889\n",
      "Overall accuracy: 0.26943 \n",
      "\n",
      " \n",
      " Added new category: clematis\n",
      "-------------Training new task: 25--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.560976\n",
      "Epoch 2, training accuracy 0.560976\n",
      "Epoch 3, training accuracy 0.567073\n",
      "Epoch 4, training accuracy 0.573171\n",
      "Epoch 5, training accuracy 0.567073\n",
      "Epoch 6, training accuracy 0.591463\n",
      "Epoch 7, training accuracy 0.603659\n",
      "Epoch 8, training accuracy 0.609756\n",
      "Epoch 9, training accuracy 0.621951\n",
      "Epoch 10, training accuracy 0.579268\n",
      "Epoch 11, training accuracy 0.609756\n",
      "Epoch 12, training accuracy 0.621951\n",
      "Epoch 13, training accuracy 0.585366\n",
      "Epoch 14, training accuracy 0.621951\n",
      "Epoch 15, training accuracy 0.628049\n",
      "Epoch 16, training accuracy 0.609756\n",
      "Epoch 17, training accuracy 0.609756\n",
      "Epoch 18, training accuracy 0.615854\n",
      "Epoch 19, training accuracy 0.615854\n",
      "Epoch 20, training accuracy 0.615854\n",
      "Epoch 21, training accuracy 0.615854\n",
      "Epoch 22, training accuracy 0.609756\n",
      "Epoch 23, training accuracy 0.615854\n",
      "Epoch 24, training accuracy 0.609756\n",
      "Epoch 25, training accuracy 0.609756\n",
      "Epoch 26, training accuracy 0.609756\n",
      "Epoch 27, training accuracy 0.609756\n",
      "Epoch 28, training accuracy 0.609756\n",
      "Epoch 29, training accuracy 0.609756\n",
      "Epoch 30, training accuracy 0.609756\n",
      "Epoch 31, training accuracy 0.615854\n",
      "Epoch 32, training accuracy 0.615854\n",
      "Epoch 33, training accuracy 0.615854\n",
      "Epoch 34, training accuracy 0.609756\n",
      "Epoch 35, training accuracy 0.609756\n",
      "Epoch 36, training accuracy 0.609756\n",
      "Epoch 37, training accuracy 0.609756\n",
      "Epoch 38, training accuracy 0.609756\n",
      "Epoch 39, training accuracy 0.615854\n",
      "Epoch 40, training accuracy 0.615854\n",
      "Epoch 41, training accuracy 0.609756\n",
      "Epoch 42, training accuracy 0.609756\n",
      "Epoch 43, training accuracy 0.591463\n",
      "Epoch 44, training accuracy 0.615854\n",
      "Epoch 45, training accuracy 0.609756\n",
      "Epoch 46, training accuracy 0.615854\n",
      "Epoch 47, training accuracy 0.603659\n",
      "Epoch 48, training accuracy 0.609756\n",
      "Epoch 49, training accuracy 0.615854\n",
      "Epoch 50, training accuracy 0.615854\n",
      "Overall accuracy: 0.266667 \n",
      "\n",
      " \n",
      " Added new category: colt's foot\n",
      "-------------Training new task: 26--------------\n",
      "-----------Started Selective Retraining-------------\n",
      "---- Selecting nodes ----\n",
      "Epoch 1, training accuracy 1\n",
      "Epoch 2, training accuracy 1\n",
      "Epoch 3, training accuracy 1\n",
      "Epoch 4, training accuracy 1\n",
      "Epoch 5, training accuracy 1\n",
      "Best accuracy achieved! \n",
      "\n",
      "\n",
      "-----------Started Dynamic Expansion------------\n",
      "Epoch 1, training accuracy 0.547945\n",
      "Epoch 2, training accuracy 0.554795\n",
      "Epoch 3, training accuracy 0.561644\n",
      "Epoch 4, training accuracy 0.568493\n",
      "Epoch 5, training accuracy 0.554795\n",
      "Epoch 6, training accuracy 0.575342\n",
      "Epoch 7, training accuracy 0.582192\n",
      "Epoch 8, training accuracy 0.561644\n",
      "Epoch 9, training accuracy 0.582192\n",
      "Epoch 10, training accuracy 0.59589\n",
      "Epoch 11, training accuracy 0.60274\n",
      "Epoch 12, training accuracy 0.582192\n",
      "Epoch 13, training accuracy 0.616438\n",
      "Epoch 14, training accuracy 0.59589\n",
      "Epoch 15, training accuracy 0.589041\n",
      "Epoch 16, training accuracy 0.636986\n",
      "Epoch 17, training accuracy 0.636986\n",
      "Epoch 18, training accuracy 0.609589\n",
      "Epoch 19, training accuracy 0.643836\n",
      "Epoch 20, training accuracy 0.630137\n",
      "Epoch 21, training accuracy 0.636986\n",
      "Epoch 22, training accuracy 0.623288\n",
      "Epoch 23, training accuracy 0.636986\n",
      "Epoch 24, training accuracy 0.636986\n",
      "Epoch 25, training accuracy 0.636986\n",
      "Epoch 26, training accuracy 0.650685\n",
      "Epoch 27, training accuracy 0.657534\n",
      "Epoch 28, training accuracy 0.636986\n",
      "Epoch 29, training accuracy 0.636986\n",
      "Epoch 30, training accuracy 0.657534\n",
      "Epoch 31, training accuracy 0.657534\n",
      "Epoch 32, training accuracy 0.643836\n",
      "Epoch 33, training accuracy 0.671233\n",
      "Epoch 34, training accuracy 0.657534\n",
      "Epoch 35, training accuracy 0.671233\n",
      "Epoch 36, training accuracy 0.657534\n",
      "Epoch 37, training accuracy 0.657534\n",
      "Epoch 38, training accuracy 0.671233\n",
      "Epoch 39, training accuracy 0.630137\n",
      "Epoch 40, training accuracy 0.678082\n",
      "Epoch 41, training accuracy 0.657534\n",
      "Epoch 42, training accuracy 0.650685\n",
      "Epoch 43, training accuracy 0.664384\n",
      "Epoch 44, training accuracy 0.657534\n",
      "Epoch 45, training accuracy 0.657534\n",
      "Epoch 46, training accuracy 0.657534\n",
      "Epoch 47, training accuracy 0.657534\n",
      "Epoch 48, training accuracy 0.650685\n",
      "Epoch 49, training accuracy 0.671233\n",
      "Epoch 50, training accuracy 0.657534\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-83c7cb821ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpansion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;31m#                 print(params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;31m#                 params['l%d/w:0' % den.den_layers] = np.concatenate([params['l%d/w:0' % den.den_layers],params['l%d/w_%d:0' % (den.den_layers,task_id)]], axis=1).tolist()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5f108dda91c3>\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mvdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mscope_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_w\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mvdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscope_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/3d_recognition_thesis/2d_recognition/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/3d_recognition_thesis/2d_recognition/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1137\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/3d_recognition_thesis/2d_recognition/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \"\"\"\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/3d_recognition_thesis/2d_recognition/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_attrs_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/3d_recognition_thesis/2d_recognition/venv/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    188\u001b[0m             if (cls._abc_negative_cache_version ==\n\u001b[1;32m    189\u001b[0m                 \u001b[0mABCMeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_invalidation_counter\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 subclass in cls._abc_negative_cache):\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# Fall back to the subclass check.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # train_data_path = '../Flower_dataset/Train'\n",
    "    # test_data_path = '../Flower_dataset/Test'\n",
    "\n",
    "    # lesser categories for faster loading during testing the code\n",
    "    train_data_path = '../Flower_dataset/temp_Train'\n",
    "    test_data_path = '../Flower_dataset/temp_Test'\n",
    "\n",
    "    # For easier disk read operation\n",
    "    np_train_path = '../Flower_dataset/extracted_features/train.npy.gz'\n",
    "    np_test_path = '../Flower_dataset/extracted_features/test.npy.gz'\n",
    "    np_train_label_path = '../Flower_dataset/extracted_features/train_labels.npy'\n",
    "    np_test_label_path = '../Flower_dataset/extracted_features/test_labels.npy'\n",
    "    np_label_name_path = '../Flower_dataset/extracted_features/label_names.npy'\n",
    "\n",
    "    batch_size = 10\n",
    "    epochs = 50\n",
    "    early_stop = 5\n",
    "\n",
    "    den = DEN()\n",
    "\n",
    "    if os.path.exists(np_train_path):\n",
    "\n",
    "        print(\"\\n..........loading dataset from numpy files..........\\n\")\n",
    "\n",
    "        with gzip.GzipFile(np_train_path, \"r\") as f:\n",
    "            train_data = np.load(f)\n",
    "        with gzip.GzipFile(np_test_path, \"r\") as f:\n",
    "            test_data = np.load(f)\n",
    "\n",
    "        train_labels = np.load(np_train_label_path)\n",
    "        test_labels = np.load(np_test_label_path)\n",
    "        label_names = np.load(np_label_name_path)\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"\\n..........loading dataset from disk..........\\n\")\n",
    "        train_data, train_labels, label_names = den.extract_data(train_data_path)\n",
    "        test_data, test_labels, _ = den.extract_data(test_data_path)\n",
    "\n",
    "        os.makedirs(os.path.dirname(np_train_path), exist_ok=True)\n",
    "\n",
    "        with gzip.GzipFile(np_train_path, \"w\") as f:\n",
    "            np.save(f, train_data)\n",
    "        with gzip.GzipFile(np_test_path, \"w\") as f:\n",
    "            np.save(f, test_data)\n",
    "\n",
    "        np.save(np_train_label_path, train_labels)\n",
    "        np.save(np_test_label_path, test_labels)\n",
    "        np.save(np_label_name_path, label_names)\n",
    "\n",
    "\n",
    "# show image using cv\n",
    "    # print(train_labels[512])\n",
    "    # cv.imshow(\"\", train_data[512])\n",
    "    # cv.waitKey(0)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    task_id = 0\n",
    "    y_conv = None\n",
    "\n",
    "    while den.last_label_index != (len(label_names) - 1):     # Loop for adding new tasks (lifelong learning)\n",
    "\n",
    "        task_id += 1\n",
    "        den.add_task(task_id, label_names)\n",
    "        param_values = dict()\n",
    "        selected = dict()\n",
    "        print(\"-------------Training new task: %d--------------\"%task_id)\n",
    "        if task_id == 1:\n",
    "            y_conv = den.build_model(task_id=task_id)\n",
    "            den.optimization()\n",
    "            _ = den.train_task(task_id=task_id, batch_size=batch_size, epochs=epochs)\n",
    "            params = den.get_params()\n",
    "        else:\n",
    "            print(\"-----------Started Selective Retraining-------------\")\n",
    "            \n",
    "            #------------------Selection-------------------\n",
    "            y_conv = den.build_model(task_id=task_id, output_len=1)\n",
    "            den.sess.run(tf.global_variables_initializer())\n",
    "            params = den.get_params()\n",
    "            den.optimization()\n",
    "            \n",
    "            print(\"---- Selecting nodes ----\")\n",
    "            _ = den.train_task(task_id=task_id, batch_size=batch_size, epochs=early_stop)\n",
    "            params = den.get_params()\n",
    "            if False:           \n",
    "                [selected, selected_prev, all_indices] = den.perform_selection(task_id=task_id, values_dict=params)\n",
    "                den.destroy_graph()\n",
    "\n",
    "                #------------------Retraining-------------------\n",
    "                print(\"---- Retraining selected nodes ----\")\n",
    "                y_conv = den.build_SR(task_id=task_id, selected=selected, output_len=1) \n",
    "                den.optimization(prev_W=selected_prev) \n",
    "                loss = den.train_task(task_id=task_id, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "                print(\"Loss: %f\"%loss)\n",
    "            \n",
    "#             if loss < den.loss_thr:\n",
    "\n",
    "            \n",
    "                #--------------Performing Union----------------\n",
    "                _vars = [(var.name, den.sess.run(var)) for var in tf.trainable_variables() if 'l' in var.name]\n",
    "\n",
    "                for item in _vars:\n",
    "                    key, values = item\n",
    "                    selected[key] = values\n",
    "\n",
    "                for i in reversed(range(1, den.den_layers+1)):\n",
    "                    if i == den.den_layers:\n",
    "                        temp_weight = params['l%d/w_%d:0' % (i, task_id)]\n",
    "                        temp_weight[np.ix_(all_indices['l%d' % i], [0])] = \\\n",
    "                            selected['l%d/w_%d:0' % (i, task_id)]\n",
    "                        params['l%d/w_%d:0' % (i, task_id)] = temp_weight\n",
    "                        params['l%d/b_%d:0' % (i, task_id)] = \\\n",
    "                            selected['l%d/b_%d:0' % (i, task_id)]\n",
    "                        # Updating output matrix structure\n",
    "                        params['l%d/w:0' % (i)] = np.concatenate([params['l%d/w:0' % (i)],params['l%d/w_%d:0' % (i,task_id)]], axis=1).tolist()\n",
    "                        params['l%d/b:0' % (i)] = np.concatenate([params['l%d/b:0' % (i)],params['l%d/b_%d:0' % (i,task_id)]], axis=0).tolist()\n",
    "                    else:\n",
    "                        temp_weight = params['l%d/w:0' % i]\n",
    "                        temp_biases = params['l%d/b:0' % i]\n",
    "                        temp_weight[np.ix_(all_indices['l%d' % i], all_indices['l%d' % (i + 1)])] = \\\n",
    "                            selected['l%d/w:0' % i]\n",
    "                        temp_biases[all_indices['l%d' % (i + 1)]] = \\\n",
    "                            selected['l%d/b:0' % i]\n",
    "                        params['l%d/w:0' % i] = temp_weight\n",
    "                        params['l%d/b:0' % i] = temp_biases\n",
    "\n",
    "            else:\n",
    "                \n",
    "                print(\"\\n-----------Started Dynamic Expansion------------\")\n",
    "                den.destroy_graph()\n",
    "                den.restore_params(task_id=task_id, trainable=False, param_values=params)\n",
    "                y_conv = den.build_model(task_id=task_id, expansion=True, output_len=den.last_label_index+1)\n",
    "                den.optimization()\n",
    "                _ = den.train_task(task_id=task_id, batch_size=batch_size, epochs=epochs, expansion=True)\n",
    "                params = den.get_params()\n",
    "#                 print(params)\n",
    "#                 params['l%d/w:0' % den.den_layers] = np.concatenate([params['l%d/w:0' % den.den_layers],params['l%d/w_%d:0' % (den.den_layers,task_id)]], axis=1).tolist()\n",
    "#                 params['l%d/b:0' % den.den_layers] = np.concatenate([params['l%d/b:0' % den.den_layers],params['l%d/b_%d:0' % (den.den_layers,task_id)]], axis=0).tolist()\n",
    "\n",
    "        den.destroy_graph()\n",
    "        den.restore_params(trainable=False, param_values=params)    # Freezes all learned weights\n",
    "                    \n",
    "        # ---------Performance-----------\n",
    "        den.predict(task_id=task_id, output_len=den.last_label_index+1)\n",
    "                    \n",
    "#         param_values = den.get_params()         # Backing-up model weights that were trained upto current task\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
